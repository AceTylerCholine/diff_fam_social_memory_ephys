{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve\n",
    "from scipy.signal import savgol_filter\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.stats import sem\n",
    "from statistics import mean\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.special import comb\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dfs(mat, pos, r_sum, c_sum, p_0, p):\n",
    "\n",
    "    (xx, yy) = pos\n",
    "    (r, c) = (len(r_sum), len(c_sum))\n",
    "\n",
    "    mat_new = []\n",
    "\n",
    "    for i in range(len(mat)):\n",
    "        temp = []\n",
    "        for j in range(len(mat[0])):\n",
    "            temp.append(mat[i][j])\n",
    "        mat_new.append(temp)\n",
    "\n",
    "    if xx == -1 and yy == -1:\n",
    "        for i in range(r-1):\n",
    "            temp = r_sum[i]\n",
    "            for j in range(c-1):\n",
    "                temp -= mat_new[i][j]\n",
    "            mat_new[i][c-1] = temp\n",
    "        for j in range(c-1):\n",
    "            temp = c_sum[j]\n",
    "            for i in range(r-1):\n",
    "                temp -= mat_new[i][j]\n",
    "            mat_new[r-1][j] = temp\n",
    "        temp = r_sum[r-1]\n",
    "        for j in range(c-1):\n",
    "            temp -= mat_new[r-1][j]\n",
    "        if temp <0:\n",
    "            return\n",
    "        mat_new[r-1][c-1] = temp\n",
    "\n",
    "        p_1 = 1\n",
    "        for x in r_sum:\n",
    "            p_1 *= math.factorial(x)\n",
    "        for y in c_sum:\n",
    "            p_1 *= math.factorial(y)\n",
    "\n",
    "        n = 0\n",
    "        for x in r_sum:\n",
    "            n += x\n",
    "        p_1 /= math.factorial(n)\n",
    "\n",
    "        for i in range(len(mat_new)):\n",
    "            for j in range(len(mat_new[0])):\n",
    "                p_1 /= math.factorial(mat_new[i][j])\n",
    "        if p_1 <= p_0 + 0.00000001:\n",
    "            #print(mat_new)\n",
    "            #print(p_1)\n",
    "            p[0] += p_1\n",
    "    else:\n",
    "        max_1 = r_sum[xx]\n",
    "        max_2 = c_sum[yy]\n",
    "        for j in range(c):\n",
    "            max_1 -= mat_new[xx][j]\n",
    "        for i in range(r):\n",
    "            max_2 -= mat_new[i][yy]\n",
    "        for k in range(min(max_1,max_2)+1):\n",
    "            mat_new[xx][yy] = k\n",
    "            if xx == r-2 and yy == c-2:\n",
    "                pos_new = (-1, -1)\n",
    "            elif xx == r-2:\n",
    "                pos_new = (0, yy+1)\n",
    "            else:\n",
    "                pos_new = (xx+1, yy)\n",
    "            _dfs(mat_new, pos_new, r_sum, c_sum, p_0, p)\n",
    "\n",
    "\n",
    "def fisher_exact(table):\n",
    "\n",
    "    row_sum = []\n",
    "    col_sum = []\n",
    "\n",
    "    for i in range(len(table)):\n",
    "        temp = 0\n",
    "        for j in range(len(table[0])):\n",
    "            temp += table[i][j]\n",
    "        row_sum.append(temp)\n",
    "    \n",
    "    for j in range(len(table[0])):\n",
    "        temp = 0\n",
    "        for i in range(len(table)):\n",
    "            temp += table[i][j]\n",
    "        col_sum.append(temp)\n",
    "\n",
    "    mat = [[0] * len(col_sum)] * len(row_sum)\n",
    "    pos = (0, 0)\n",
    "\n",
    "    p_0 = 1\n",
    "\n",
    "    for x in row_sum:\n",
    "        p_0 *= math.factorial(x)\n",
    "    for y in col_sum:\n",
    "        p_0 *= math.factorial(y)\n",
    "\n",
    "    n = 0\n",
    "    for x in row_sum:\n",
    "        n += x\n",
    "    p_0 /= math.factorial(n)\n",
    "\n",
    "    for i in range(len(table)):\n",
    "        for j in range(len(table[0])):\n",
    "            p_0 /= math.factorial(table[i][j])\n",
    "\n",
    "    p = [0]\n",
    "    _dfs(mat, pos, row_sum, col_sum, p_0, p)\n",
    "\n",
    "    return p[0]\n",
    "\n",
    "\n",
    "def get_spiketrain(timestamp_array, timebin =1, sampling_rate=20000):\n",
    "    \"\"\"\n",
    "    creates a spiketrain of ms time bins \n",
    "    each array element is the number of spikes recorded per ms\n",
    "    \n",
    "    Args (3 total):\n",
    "        timestamp_array: numpy array, spike timestamp array\n",
    "        timebin: int, default=1, timebin (ms) of resulting spiketrain\n",
    "        sampling_rate: int, default=20000, sampling rate in Hz of the ephys recording\n",
    "        \n",
    "    Returns (1):\n",
    "        spiketrain: numpy array, array elements are number of spikes per timebin\n",
    "    \"\"\"\n",
    "    \n",
    "    hz_to_timebin = int(sampling_rate*.001*timebin)\n",
    "    spiketrain = np.histogram(timestamp_array, bins=np.arange(0, timestamp_array[-1], hz_to_timebin))[0]\n",
    "    \n",
    "    return spiketrain\n",
    "\n",
    "\n",
    "def get_firing_rate(spiketrain, smoothing_window = 250, timebin=1):\n",
    "    \"\"\"\n",
    "    calculates firing rate (spikes/second)\n",
    "    \n",
    "    Args (3 total, 1 required):\n",
    "        spiketrain: numpy array, in timebin (ms) bins\n",
    "        smoothing_window: int, default=250, smoothing average window (ms)\n",
    "            min smoothing_window = 1\n",
    "        timebin: int, default = 1, timebin (ms) of spiketrain\n",
    "\n",
    "    Return (1):\n",
    "        firing_rate: numpy array of firing rates in timebin sized windows\n",
    "        \n",
    "    \"\"\" \n",
    "    weights = np.ones(smoothing_window) / smoothing_window * 1000 / timebin \n",
    "    firing_rate = np.convolve(spiketrain, weights, mode='same')\n",
    "\n",
    "    return firing_rate\n",
    "\n",
    "\n",
    "def get_event_lengths(events):\n",
    "    \"\"\"\n",
    "    calculates event lengths and longest event length\n",
    "\n",
    "    Args (1):\n",
    "        events:numpy array of [[start (ms), stop (ms)] x n events]\n",
    "\n",
    "    Returns (2):\n",
    "        max event length: int, longest event length in ms\n",
    "        event_lengths: lst of ints, event lengths in ms\n",
    "    \"\"\"\n",
    "    event_lengths = []\n",
    "    for i in range(events.shape[0]):\n",
    "        event_length = int(events[i][1] - events[i][0])\n",
    "        event_lengths.append(event_length)\n",
    "    return max(event_lengths), event_lengths, mean(event_lengths)\n",
    "\n",
    "\n",
    "def trim_event(event, max_event):\n",
    "    \"\"\"\n",
    "    trims events to a given length\n",
    "    Args (2 total):\n",
    "        events:numpy array of [[start (ms), stop (ms)] x n events]\n",
    "        max_event: int, max length (s) of event desired\n",
    "\n",
    "    Returns (1):\n",
    "        events:numpy array of [[start (ms), stop (ms)] x n events]\n",
    "        with none longer than max_event\n",
    "    \"\"\"\n",
    "    if event[1] - event[0] > (max_event*1000):\n",
    "        event[1] = event[0]+(max_event*1000)\n",
    "        event[0] = event[0]  \n",
    "    return np.array(event)\n",
    "\n",
    "\n",
    "def pre_event_window(event, baseline_window):\n",
    "    \"\"\"\n",
    "    creates an event like object np.array[start(ms), stop(ms)] for\n",
    "    baseline_window amount of time prior to an event\n",
    "\n",
    "    Args (2 total):\n",
    "        event: np.array[start(ms), stop(ms)]\n",
    "        baseline_window: int, seconds prior to an event\n",
    "\n",
    "    Returns (1):\n",
    "        preevent: np.array, [start(ms),stop(ms)] baseline_window (s) before event\n",
    "    \"\"\"\n",
    "    preevent = [event[0] - (baseline_window*1000)-1, event[0]-1]\n",
    "    return np.array(preevent)\n",
    "\n",
    "\n",
    "def max_events(unit_dict, max_event, pre_window, timebin = 1):\n",
    "    \"\"\"\n",
    "    creates a dictionary with unit firing rates during events no longer\n",
    "    than max_event (s) (all longer events will be trimmed) and start times\n",
    "    adjusted to include pre_window time (s)\n",
    "\n",
    "    Args (4 total):\n",
    "        unit_dict: dict, unit id as keys, and values are spiketrains or firing rates \n",
    "        max_event: int, longest event length (s) returned (all longer events will be trimmed)\n",
    "        pre_window: int, amount of preevent time (s) returned\n",
    "        timebin: timebin (ms) of dict\n",
    "\n",
    "    Returns (1):\n",
    "        snippets_dict: dict, unit id as keys, values are spiketrains or firing rates during\n",
    "        pre_window and up until max event \n",
    "    \"\"\"\n",
    "    \n",
    "    snippets_dict = {}\n",
    "    for unit in unit_dict.keys():\n",
    "        events = unit_dict[unit]\n",
    "        try:\n",
    "            events = [event[0:int((pre_window + max_event)*1000/timebin)] for event in events]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        snippets_dict[unit] = events\n",
    "    return snippets_dict\n",
    "\n",
    "\n",
    "def get_unit_average_events(unit_event_snippets):\n",
    "    unit_average_event = {}\n",
    "    for unit in unit_event_snippets.keys():\n",
    "        unit_average_event[unit] = np.mean(unit_event_snippets[unit], axis=0)\n",
    "    return unit_average_event\n",
    "\n",
    "\n",
    "class EphysRecording:\n",
    "    \"\"\"\n",
    "    A class for an ephys recording after being spike sorted and manually curated using phy. \n",
    "    Ephys recording must have a phy folder. \n",
    "\n",
    "    Attributes:\n",
    "        path: str, relative path to the phy folder\n",
    "            formatted as: './folder/folder/phy'\n",
    "        sampling_rate: int, sampling rate of the ephys device\n",
    "            in Hz, standard in the PC lab is 20,000Hz\n",
    "        timestamps_var: numpy array, all spike timestamps \n",
    "            of good and mua units (no noise unit-generated spikes)\n",
    "        unit_array: numpy array, unit ids associated with each\n",
    "            spike in the timestamps_var\n",
    "        labels_dict: dict, keys are unit ids (str) and\n",
    "            values are labels (str)\n",
    "        unit_timestamps: dict, keys are unit ids (int), and\n",
    "            values are numpy arrays of timestamps for all spikes \n",
    "            from \"good\" units only \n",
    "\n",
    "    Methods: (all called in __init__)\n",
    "        get_unit_labels: creates labels_dict\n",
    "        get_spike_specs: creates timestamps_var and unit_array\n",
    "        get_unit_timestamps: creates unit_timestamps dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path, sampling_rate=20000):\n",
    "        \"\"\"\n",
    "        constructs all necessary attributes for the EphysRecording object\n",
    "        including creating labels_dict, timestamps_var, and a unit_timstamps \n",
    "        dictionary \n",
    "        \n",
    "        Arguments (2 total):\n",
    "            path: str, relative path to the phy folder\n",
    "                formatted as: './folder/folder/phy'\n",
    "            sampling_rate: int, default=20000; sampling rate of \n",
    "                the ephys device in Hz\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.get_unit_labels()\n",
    "        self.get_spike_specs()\n",
    "        self.get_unit_timestamps()\n",
    "\n",
    "    \n",
    "    def get_unit_labels(self):\n",
    "        \"\"\"\n",
    "        assigns self.labels_dicts as a dictionary \n",
    "        with unit id (str) as key and label as values (str)\n",
    "        labels: 'good', 'mua', 'noise' \n",
    "\n",
    "        Arguments:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        labels = 'cluster_group.tsv'\n",
    "        with open(os.path.join(self.path, labels), 'r') as f:\n",
    "            reader = csv.DictReader(f, delimiter='\\t')\n",
    "            self.labels_dict = {row['cluster_id']: row['group'] for row in reader}\n",
    "\n",
    "    \n",
    "    def get_spike_specs(self):\n",
    "        \"\"\"\n",
    "        imports spike_time and spike_unit from phy folder\n",
    "        deletes spikes from units labeled noise in unit and timestamp array\n",
    "        and assigns self.timstamps_var (numpy array) as the remaining timestamps \n",
    "        and assigns self.unit_array (numpy array) as the unit ids associated\n",
    "        with each spike\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            None \n",
    "        \"\"\"\n",
    "        timestamps = 'spike_times.npy'\n",
    "        unit = 'spike_clusters.npy'\n",
    "        timestamps_var = np.load(os.path.join(self.path, timestamps))\n",
    "        unit_array = np.load(os.path.join(self.path, unit))\n",
    "        spikes_to_delete = []\n",
    "        for spike in range(len(timestamps_var)): \n",
    "            if self.labels_dict[unit_array[spike].astype(str)] == 'noise':\n",
    "                spikes_to_delete.append(spike)\n",
    "        self.timestamps_var = np.delete(timestamps_var, spikes_to_delete)\n",
    "        self.unit_array = np.delete(unit_array, spikes_to_delete)\n",
    "\n",
    "    \n",
    "    def get_unit_timestamps(self):\n",
    "        \"\"\"\n",
    "        creates a dictionary of units to spike timestamps\n",
    "        keys are unit ids (int) and values are spike timestamps for that unit (numpy arrays)\n",
    "        and assigns dictionary to self.unit_timestamps\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "        \n",
    "        Return:\n",
    "            None\n",
    "        \"\"\"\n",
    "        \n",
    "        unit_timestamps = {}\n",
    "        for spike in range(len(self.timestamps_var)): \n",
    "            if self.unit_array[spike] in unit_timestamps.keys():\n",
    "                timestamp_list = unit_timestamps[self.unit_array[spike]] \n",
    "                timestamp_list = np.append(timestamp_list, self.timestamps_var[spike])\n",
    "                unit_timestamps[self.unit_array[spike]] = timestamp_list\n",
    "            else:\n",
    "                unit_timestamps[self.unit_array[spike]] = self.timestamps_var[spike]\n",
    "        \n",
    "        self.unit_timestamps = unit_timestamps   \n",
    "\n",
    "\n",
    "class MultiEvents:\n",
    "    \"\"\"\n",
    "    A class for an event triggered average object that needs\n",
    "    an EphysRecording class instance \n",
    "    and an event array [[start (ms), stop(ms)]..]\n",
    "    \n",
    "\n",
    "    Attributes:\n",
    "        event: str, name of the event \n",
    "        events: numpy array of [[start (ms), stop (ms)] x n events]\n",
    "        smoothing_window: int, default=250, window length in ms used to calculate firing rates\n",
    "        timebin: int, default=1, bin size (in ms) for spike train and firing rate arrays\n",
    "        ingore_freq: int, default=0, frequency in Hz that a good unit needs to fire at to be included in analysis\n",
    "        longest_event: int, length of longest event (ms)\n",
    "        event_lengths: lst, length of all events (ms)\n",
    "        spiketrain: numpy array, each element of the array \n",
    "            is the number of spikes per timebin throughout the whole recording\n",
    "        unit_spiketrains: dict, keys are unit ids (int), values (numpy arrays) are each \"good\"\n",
    "            units spiketrains in the specified timebins for the whole recording\n",
    "        unit_firing_rates: dict, keys are unit ids (int), values (numpy array) are each \"good\"\n",
    "            units firing rates calculated using smoothing_window in bins of size timebin\n",
    "\n",
    "    Methods: \n",
    "        get_whole_spiketrain: \n",
    "        get_unit_spiketrains: \n",
    "        get_unit_firing_rates: \n",
    "        get_event_snippets:\n",
    "        get_unit_event_firing_rates:\n",
    "        wilcox_baseline_v_event_stats:\n",
    "        wilcox_baseline_v_event_plots:\n",
    "    \"\"\"\n",
    "    def __init__(self, event_dict, recording, smoothing_window=250, timebin=1, ignore_freq=0):\n",
    "        \n",
    "        self.recording = recording\n",
    "        self.event_dict = event_dict\n",
    "        self.events = event_dict.keys()\n",
    "        self.events = [value for sublist in event_dict.values() for value in sublist]\n",
    "        self.smoothing_window = smoothing_window\n",
    "        self.timebin = timebin\n",
    "        self.ignore_freq = ignore_freq\n",
    "        self.longest_event, self.event_lengths, self.mean_event_length = get_event_lengths(self.events)\n",
    "        self.get_whole_spiketrain()\n",
    "        self.get_unit_spiketrains()\n",
    "        self.get_unit_firing_rates()\n",
    "\n",
    "    \n",
    "    def get_whole_spiketrain(self):\n",
    "        \"\"\"\n",
    "        creates a spiketrain of ms time bins \n",
    "        each array element is the number of spikes recorded per ms\n",
    "        \n",
    "        Args (1 total):\n",
    "            timestamp_array: numpy array, spike timestamp array\n",
    "            \n",
    "        Returns (1):\n",
    "            spiketrain_ms_timebins: a numpy array \n",
    "                array elements are number of spikes per ms \n",
    "        \"\"\"\n",
    "        self.spiketrain = get_spiketrain(self.recording.timestamps_var, self.recording.sampling_rate, self.timebin)\n",
    "\n",
    "    \n",
    "    def get_unit_spiketrains(self):  \n",
    "        \"\"\"\n",
    "        Creates a dictionary and assigns it as self.unit_spiketrains\n",
    "        where keys are 'good' unit ids (int) (not 'mua') that reach\n",
    "        a threhold frequency, values are numpy arrays of \n",
    "        spiketrains in timebin sized bins\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "            \n",
    "        Reutrns:\n",
    "            None\n",
    "            \n",
    "        \"\"\"\n",
    "        unit_spiketrains = {}\n",
    "        for unit in self.recording.unit_timestamps.keys():\n",
    "            if self.recording.labels_dict[str(unit)] == 'good':\n",
    "                no_spikes = len(self.recording.unit_timestamps[unit])\n",
    "                unit_freq = no_spikes/self.recording.timestamps_var[-1]*self.recording.sampling_rate\n",
    "                if unit_freq > self.ignore_freq:\n",
    "                    unit_spiketrains[unit] = get_spiketrain(self.recording.unit_timestamps[unit], \n",
    "                                                            self.recording.sampling_rate, self.timebin)\n",
    "        self.unit_spiketrains = unit_spiketrains    \n",
    "\n",
    "    \n",
    "    def get_unit_firing_rates(self):  \n",
    "        \"\"\"\n",
    "        Calculates firing rates per unit,\n",
    "        creates a dictionary and assigns it as self.unit_firing_rates\n",
    "        the keys are unit ids (int) and values are firing rates for the\n",
    "        unit (numpy array) in timebin sized bins \n",
    "        calculated using smoothing_window for averaging\n",
    "        \n",
    "        Args:\n",
    "            none\n",
    "            \n",
    "        Returns:\n",
    "            none\n",
    "        \"\"\"\n",
    "        unit_firing_rates = {}\n",
    "        for unit in self.unit_spiketrains.keys():\n",
    "            unit_firing_rates[unit] = get_firing_rate(self.unit_spiketrains[unit], self.smoothing_window, self.timebin)\n",
    "        self.unit_firing_rates = unit_firing_rates\n",
    "\n",
    "    \n",
    "    def get_event_snippets(self, event, whole_recording, pre_window=0, post_window=0, equalize = False):\n",
    "        \"\"\"\n",
    "        takes snippets of spiketrains or firing rates for events\n",
    "        optional pre-event and post-event windows (s) may be included\n",
    "        all events can also be of equal length by extending \n",
    "        snippet lengths to the longest event\n",
    "    \n",
    "        Args (5 total, 1 required): \n",
    "            whole_recording: numpy array, spiketrain or firing rates \n",
    "                for the whole recording, for population or for a single unit\n",
    "            pre_window: int, default=0, seconds prior to start of event returned\n",
    "            post_window: int, default=0, seconds after end of event returned\n",
    "            equalize: {'max', average'}, default=False, equalizes lengths of events\n",
    "                by padding with post event time or trimming event\n",
    "                'max': makes all events as long as the longest event \n",
    "                'average': makes all events as long as the average event length \n",
    "            events:numpy array of [[start (ms), stop (ms)] x n events], \n",
    "                default=None in which case self.events is used\n",
    "    \n",
    "        Returns (1):\n",
    "            event_snippets: a list of lists, where each list is a list of firing rates\n",
    "                or spiketrains during an event including pre_window&post_windows, \n",
    "                accounting for equalize and timebins\n",
    "        \"\"\"\n",
    "        \n",
    "        if event in self.event_dict.keys():\n",
    "            events = self.event_dict[event]\n",
    "        event_snippets = []\n",
    "        pre_window = math.ceil(pre_window*1000)\n",
    "        post_window = math.ceil(post_window*1000)\n",
    "        for i in range(events.shape[0]):\n",
    "            if equalize == 'max':\n",
    "                event_diff = math.ceil(self.longest_event - self.event_lengths[i])\n",
    "            if equalize == 'average':\n",
    "                event_diff = math.ceil(self.mean_event_length - self.event_lengths[i])\n",
    "            else:\n",
    "                event_diff = 0\n",
    "            pre_event = math.ceil((events[i][0] - pre_window)/self.timebin)\n",
    "            post_event = math.ceil((events[i][1] + post_window + event_diff)/self.timebin)\n",
    "            event_snippet = whole_recording[pre_event:post_event]\n",
    "            event_snippets.append(event_snippet)\n",
    "        return event_snippets\n",
    "    \n",
    "    def get_unit_event_firing_rates(self, event, pre_window = 0, post_window = 0, equalize = False):\n",
    "        \"\"\"\n",
    "        returns firing rates for events per unit\n",
    "    \n",
    "        Args (6 total, 1 required):\n",
    "            smoothing_window: int, default=250, smoothing average window (ms)\n",
    "                min smoothing_window = 1 \n",
    "            timebin: int, default 1, timebin in ms for firing rate array\n",
    "            pre_window: int, default=0, seconds prior to start of event returned\n",
    "            post_window: int, default=0, seconds after end of event returned\n",
    "            equalize: {'max', average'}, default=False, equalizes lengths of events\n",
    "                by padding with post event time or trimming event\n",
    "                'max': makes all events as long as the longest event \n",
    "                'average': makes all events as long as the average event length \n",
    "            events:numpy array of [[start (ms), stop (ms)] x n events], \n",
    "                default=None in which case self.events is used\n",
    "            \n",
    "        Return (1):\n",
    "            unit_event_firing_rates: dict, keys are unit ids (???),\n",
    "            values are lsts of numpy arrays of firing rates per event\n",
    "        \"\"\"\n",
    "        unit_event_firing_rates = {}\n",
    "        for unit in self.unit_spiketrains.keys():\n",
    "            unit_event_firing_rates[unit] = self.get_event_snippets(event, self.unit_firing_rates[unit], pre_window, post_window, equalize, events)\n",
    "        return unit_event_firing_rates\n",
    "\n",
    "    def wilcox_baseline_v_event_stats(self, event, baseline_window, max_event=None, equalize = 'average'):\n",
    "        #what if i wanted a random snippet from the first ten minutes instead of prior to the event?\n",
    "        \"\"\"\n",
    "        calculates wilcoxon signed-rank test for average firing rates of two windows: event vs baseline\n",
    "        baseline used is an amount of time immediately prior to the event\n",
    "        wilcoxon signed-rank test is applied to two sets of measurements:\n",
    "        average firing rate per event, average firing rate per baseline\n",
    "        \n",
    "        Args (3 total, 1 required):\n",
    "            baseline_window: int, length of baseline firing rate (s)\n",
    "            max_event: int, default=None, max length of an event (s)\n",
    "            equalize: Boolean, default=False, if True, equalizes lengths of each event to longest event\n",
    "    \n",
    "        Return (1):\n",
    "            wilcoxon_df: pandas dataframe, columns are unit ids, \n",
    "            row[0] are wilcoxon statistics and row[1] are p values \n",
    "        \n",
    "        \"\"\"\n",
    "        preevent_baselines = np.array([pre_event_window(event, baseline_window) for event in self.event_dict[event]])\n",
    "        unit_preevent_firing_rates = self.get_unit_event_firing_rates(preevent_baselines, 0, 0, False)\n",
    "        unit_event_firing_rates = self.get_unit_event_firing_rates(0,0,equalize)\n",
    "        if equalize == 'average':\n",
    "            self.wilcox_xstop = self.mean_event_length\n",
    "        if equalize == 'max':\n",
    "            self.wilcox_xstop = self.longest_event\n",
    "        if max_event is not None:\n",
    "            unit_event_firing_rates = max_events(unit_event_firing_rates, max_event, 0, self.timebin)\n",
    "        unit_averages = {}\n",
    "        for unit in unit_event_firing_rates.keys():\n",
    "            try:\n",
    "                event_averages = [mean(event) for event in unit_event_firing_rates[unit]]\n",
    "                preevent_averages = [mean(event) for event in unit_preevent_firing_rates[unit]]\n",
    "                unit_averages[unit] = [event_averages, preevent_averages]\n",
    "            except:\n",
    "                print(f'Unit {unit} has {len(self.recording.unit_timestamps[unit])} spikes')\n",
    "        wilcoxon_stats = {}\n",
    "        for unit in unit_averages.keys(): \n",
    "            wilcoxon_stats[unit] = wilcoxon(unit_averages[unit][0], unit_averages[unit][1], method = 'approx')\n",
    "        wilcoxon_df = pd.DataFrame.from_dict(wilcoxon_stats)\n",
    "        wilcoxon_df.index = ['Wilcoxon Stat', 'p value']\n",
    "        self.wilcox_baseline = baseline_window\n",
    "        self.wilcox_maxevent = max_event\n",
    "        return wilcoxon_df\n",
    "\n",
    "    def fishers_exact_wilcox(self, baseline_window, max_event=None, equalize = 'average'):\n",
    "        sig_units = {}\n",
    "        for event in self.event_dict.keys():\n",
    "            wilcox_df = self.wilcox_baseline_v_event_stats(event, baseline_window, max_event, equalize) \n",
    "            sig_units[event] = (len(wilcox_df[(wilcox_df[1]<=0.05)]), len(wilcox_df[(wilcox_df[1]>.05)])) \n",
    "        fishers_df = pd.DataFrame(sig_units.values(), index=sig_units.keys(), columns=['Significant', 'Not Significant'])\n",
    "\n",
    "                        \n",
    "\n",
    "    def wilcox_baseline_v_event_plots(self, title, p_value=None, units=None):\n",
    "        \"\"\"\n",
    "        plots event triggered average firing rates for units\n",
    "        all events need to be the same length\n",
    "\n",
    "        Args(3 total, 1 required):\n",
    "            title: str, title of figure\n",
    "            p_value: int, default=None, all p values less than will be plotted\n",
    "            units: lst, default=None, list of unit ids (ints) to be plotted\n",
    "\n",
    "        Returns:\n",
    "            none\n",
    "        \"\"\" \n",
    "        units_to_plot = []\n",
    "        if p_value is not None:\n",
    "            for unit in self.wilcoxon_df.columns.tolist():\n",
    "                if self.wilcoxon_df[unit][1] < p_value:\n",
    "                      units_to_plot.append(unit)\n",
    "        else:\n",
    "            if units is None:\n",
    "                units_to_plot = self.wilcoxon_df.columns.tolist()\n",
    "            else:\n",
    "                units_to_plot = units\n",
    "        no_plots = len(units_to_plot)\n",
    "        height_fig = math.ceil(no_plots/3)\n",
    "        i = 1\n",
    "        plt.figure(figsize=(20,4*height_fig))\n",
    "        unit_event_firing_rates = self.get_unit_event_firing_rates(self.wilcox_baseline, 0, True)\n",
    "        if self.wilcox_maxevent is not None:\n",
    "            unit_event_firing_rates = max_events(unit_event_firing_rates, self.wilcox_maxevent, self.wilcox_baseline)\n",
    "            x_stop = self.wilcox_maxevent\n",
    "        else:\n",
    "            x_stop = self.wilcox_xstop\n",
    "        for unit in units_to_plot:\n",
    "            mean_arr = np.mean(unit_event_firing_rates[unit], axis=0)\n",
    "            sem_arr = sem(unit_event_firing_rates[unit], axis=0)\n",
    "            p_value = self.wilcoxon_df[unit][1]\n",
    "            x = np.linspace(start=-self.wilcox_baseline,stop=x_stop,num=len(mean_arr))\n",
    "            plt.subplot(height_fig,3,i)\n",
    "            plt.plot(x, mean_arr, c= 'b')\n",
    "            plt.axvline(x=0, color='r', linestyle='--')\n",
    "            plt.fill_between(x, mean_arr-sem_arr, mean_arr+sem_arr, alpha=0.2)\n",
    "            plt.title(f'Unit {unit} Average (p={p_value})')\n",
    "            i+=1\n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "\n",
    "    def wilcoxon_average_firingrates(self, event1, event2, max_event=None, equalize = 'average'):\n",
    "        #what if i wanted a random snippet from the first ten minutes instead of prior to the event?\n",
    "        \"\"\"\n",
    "        calculates wilcoxon signed-rank test for average firing rates of two windows: event vs baseline\n",
    "        baseline used is an amount of time immediately prior to the event\n",
    "        wilcoxon signed-rank test is applied to two sets of measurements:\n",
    "        average firing rate per event, average firing rate per baseline\n",
    "        \n",
    "        Args (3 total, 1 required):\n",
    "            baseline_window: int, length of baseline firing rate (s)\n",
    "            max_event: int, default=None, max length of an event (s)\n",
    "            equalize: {'max', average'}, default=False, equalizes lengths of events\n",
    "                by padding with post event time or trimming event\n",
    "                'max': makes all events as long as the longest event \n",
    "                'average': makes all events as long as the average event length \n",
    "    \n",
    "        Return (1):\n",
    "            wilcoxon_df: pandas dataframe, columns are unit ids, \n",
    "            row[0] are wilcoxon statistics and row[1] are p values \n",
    "        \n",
    "        \"\"\"\n",
    "        unit_event1_firing_rates = self.get_unit_event_firing_rates(event1, 0, 0, equalize)\n",
    "        unit_event2_firing_rates = self.get_unit_event_firing_rates(event2, 0, 0, equalize)\n",
    "        if max_event is not None:\n",
    "            unit_event1_firing_rates = max_events(unit_event1_firing_rates, max_event, 0, self.timebin)\n",
    "            unit_event2_firing_rates = max_events(unit_event2_firing_rates, max_event, 0, self.timebin)\n",
    "        unit_averages = {}\n",
    "        for unit in unit_event1_firing_rates.keys():\n",
    "            try:\n",
    "                event1_averages = [mean(event) for event in unit_event1_firing_rates[unit]]\n",
    "                event2_averages = [mean(event) for event in unit_event2_firing_rates[unit]]\n",
    "                unit_averages[unit] = [event1_averages, event2_averages]\n",
    "            except:\n",
    "                print(f'Unit {unit} has {len(self.recording.unit_timestamps[unit])} spikes')\n",
    "        wilcoxon_stats = {}\n",
    "        for unit in unit_averages.keys(): \n",
    "            wilcoxon_stats[unit] = wilcoxon(unit_averages[unit][0], unit_averages[unit][1], method = 'approx')\n",
    "        wilcoxon_df = pd.DataFrame.from_dict(wilcoxon_stats)\n",
    "        self.wilcoxon_df = wilcoxon_df\n",
    "\n",
    "    def get_zscore(self, event, baseline_window, equalize = 'average'):\n",
    "        #nancy had a matrix of (neuron, timebin, trial)\n",
    "        event = self.event_dict[event]\n",
    "        preevent_baselines = np.array([pre_event_window(event, baseline_window) for event in self.event])\n",
    "        unit_event_firing_rates = self.get_unit_event_firing_rates( baseline_window, 0, equalize)\n",
    "        unit_preevent_firing_rates = self.get_unit_event_firing_rates(0,0,False,preevent_baselines)\n",
    "        zscored_events = {}\n",
    "        for unit in unit_event_firing_rates:\n",
    "            #calculate average event across all events per unit\n",
    "            event_average = np.mean(unit_event_firing_rates[unit], axis = 0)\n",
    "            #one average for all preevents \n",
    "            preevent_average = np.mean(unit_preevent_firing_rates[unit], axis = 0)\n",
    "            mew = np.mean(preevent_average)\n",
    "            sigma = np.std(preevent_average)\n",
    "            zscored_event = [(event_bin - mew)/sigma for event_bin in event_average]\n",
    "            zscored_events[unit] = zscored_event\n",
    "        self.zscored_events = zscored_events\n",
    "        self.zscore_baseline = baseline_window\n",
    "        \n",
    "    def get_zcore_plot(self, max_event, title):\n",
    "        plt.figure(figsize=(20,6))\n",
    "        baseline_window = self.zscore_baseline\n",
    "        zscored_unit_event_firing_rates = self.zscored_events\n",
    "        if max_event is not None:\n",
    "            zscored_unit_event_firing_rates = max_events(zscored_unit_event_firing_rates, max_event, baseline_window)\n",
    "        zscore_pop = np.array(list(zscored_unit_event_firing_rates.values()))\n",
    "        mean_arr = np.mean(zscore_pop, axis=0)\n",
    "        sem_arr = sem(zscore_pop, axis=0)\n",
    "        x = np.linspace(start=-baseline_window,stop=max_event,num=len(mean_arr))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(x, mean_arr, c= 'b')\n",
    "        plt.axvline(x=0, color='r', linestyle='--')\n",
    "        plt.fill_between(x, mean_arr-sem_arr, mean_arr+sem_arr, alpha=0.2)\n",
    "        plt.title(f'Population z-score {self.event} event')\n",
    "        plt.subplot(1,2,2)\n",
    "        for unit in zscored_unit_event_firing_rates.keys():\n",
    "            plt.plot(x, zscored_unit_event_firing_rates[unit], linewidth = .5)\n",
    "            plt.axvline(x=0, color='r', linestyle='--')\n",
    "            plt.title(f'Unit z-score {self.event} event')\n",
    "        plt.suptitle(f'{title} Z-scored average {self.event} event')\n",
    "        plt.show()        \n",
    "\n",
    "    def PCA_trajectories(self, pre_window = 0, post_window = 0, equalize = 'average'):\n",
    "        first_event = True\n",
    "        for event in self.event_dict.keys():\n",
    "            unit_event_firing_rates = self.get_unit_event_firing_rates(self, event, pre_window, post_window, equalize)\n",
    "            unit_event_average = get_unit_average_events(unit_event_firing_rates) \n",
    "            if first_event:\n",
    "                PCA_matrix = [value for sublist in unit_event_average.values() for value in sublist]\n",
    "                PCA_key = [event] * len(PCA_matrix)\n",
    "                first_event = False\n",
    "            else:\n",
    "                next_event = [value for sublist in unit_event_average.values() for value in sublist]\n",
    "                PCA_matrix = np.concatenate([PCA_matrix, next_event], axis=0)\n",
    "                next_event_key = [event] * len(next_event)\n",
    "                PCA_key = PCA_key + next_event_key\n",
    "        pca = PCA(n_components = 2)\n",
    "        transformed_matrix = pca.fit_transform(PCA_matrix)\n",
    "        self.PCA_trajectories = transformed_matrix\n",
    "        self.PCA_key = PCA_key\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = [[2,11],[9,3],[6,11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "13 2\n",
      "12 9\n",
      "17 6\n",
      "0.0008339376143568793\n"
     ]
    }
   ],
   "source": [
    "n = sum(sum(row) for row in observed)\n",
    "print(n)\n",
    "nums = 1\n",
    "denom_sum = 0\n",
    "for i in range(len(observed)):\n",
    "    denom_sum = observed[i][0] + denom_sum\n",
    "    nums *= comb(sum(observed[i]),observed[i][0])\n",
    "    print(sum(observed[i]),observed[i][0])\n",
    "denom = comb(n, denom_sum)\n",
    "p_fisher = nums/ denom\n",
    "print(p_fisher)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "play",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
