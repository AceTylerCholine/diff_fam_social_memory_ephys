{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve\n",
    "from scipy.signal import savgol_filter\n",
    "import math\n",
    "import boris_extraction as boris\n",
    "import pandas as pd\n",
    "from scipy.stats import sem\n",
    "from statistics import mean\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do\n",
    "\n",
    "# test multirecording code\n",
    "# specfically recording = name of object or object\n",
    "# test PCA code\n",
    "# write doc_strings for zscore and pca code  \n",
    "\n",
    "# rearrange attributes of recordings vs event functions\n",
    "\n",
    "# write code to add event dict to recordings \n",
    "# as well as subject per recording\n",
    "# either as a batch process or individually (code for both) \n",
    "\n",
    "# add exporting functions for all data (collection) or some data (per recording) \n",
    "# add fishers exact test code somewhere \n",
    "\n",
    "# figure out this equalize parameter\n",
    "# potentially get rid of all options except user_defined \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_spiketrain(timestamp_array, timebin =1, sampling_rate=20000):\n",
    "    \"\"\"\n",
    "    creates a spiketrain of ms time bins \n",
    "    each array element is the number of spikes recorded per ms\n",
    "    \n",
    "    Args (3 total):\n",
    "        timestamp_array: numpy array, spike timestamp array\n",
    "        timebin: int, default=1, timebin (ms) of resulting spiketrain\n",
    "        sampling_rate: int, default=20000, sampling rate in Hz of the ephys recording\n",
    "        \n",
    "    Returns (1):\n",
    "        spiketrain: numpy array, array elements are number of spikes per timebin\n",
    "    \"\"\"\n",
    "    \n",
    "    hz_to_timebin = int(sampling_rate*.001*timebin)\n",
    "    spiketrain = np.histogram(timestamp_array, bins=np.arange(0, timestamp_array[-1], hz_to_timebin))[0]\n",
    "    \n",
    "    return spiketrain\n",
    "\n",
    "def get_firing_rate(spiketrain, smoothing_window = 250, timebin=1):\n",
    "    \"\"\"\n",
    "    calculates firing rate (spikes/second)\n",
    "    \n",
    "    Args (3 total, 1 required):\n",
    "        spiketrain: numpy array, in timebin (ms) bins\n",
    "        smoothing_window: int, default=250, smoothing average window (ms)\n",
    "            min smoothing_window = 1\n",
    "        timebin: int, default = 1, timebin (ms) of spiketrain\n",
    "\n",
    "    Return (1):\n",
    "        firing_rate: numpy array of firing rates in timebin sized windows\n",
    "        \n",
    "    \"\"\" \n",
    "    weights = np.ones(smoothing_window) / smoothing_window * 1000 / timebin \n",
    "    firing_rate = np.convolve(spiketrain, weights, mode='same')\n",
    "\n",
    "    return firing_rate\n",
    "\n",
    "\n",
    "def get_event_lengths(events):\n",
    "    \"\"\"\n",
    "    calculates event lengths and longest event length\n",
    "\n",
    "    Args (1):\n",
    "        events:numpy array of [[start (ms), stop (ms)] x n events]\n",
    "\n",
    "    Returns (2):\n",
    "        max event length: int, longest event length in ms\n",
    "        event_lengths: lst of ints, event lengths in ms\n",
    "    \"\"\"\n",
    "    event_lengths = []\n",
    "    for i in range(events.shape[0]):\n",
    "        event_length = int(events[i][1] - events[i][0])\n",
    "        event_lengths.append(event_length)\n",
    "    return max(event_lengths), event_lengths, mean(event_lengths)\n",
    "\n",
    "\n",
    "def trim_event(event, max_event):\n",
    "    \"\"\"\n",
    "    trims events to a given length\n",
    "    Args (2 total):\n",
    "        events:numpy array of [[start (ms), stop (ms)] x n events]\n",
    "        max_event: int, max length (s) of event desired\n",
    "\n",
    "    Returns (1):\n",
    "        events:numpy array of [[start (ms), stop (ms)] x n events]\n",
    "        with none longer than max_event\n",
    "    \"\"\"\n",
    "    if event[1] - event[0] > (max_event*1000):\n",
    "        event[1] = event[0]+(max_event*1000)\n",
    "        event[0] = event[0]  \n",
    "    return np.array(event)\n",
    "\n",
    "\n",
    "def pre_event_window(event, baseline_window):\n",
    "    \"\"\"\n",
    "    creates an event like object np.array[start(ms), stop(ms)] for\n",
    "    baseline_window amount of time prior to an event\n",
    "\n",
    "    Args (2 total):\n",
    "        event: np.array[start(ms), stop(ms)]\n",
    "        baseline_window: int, seconds prior to an event\n",
    "\n",
    "    Returns (1):\n",
    "        preevent: np.array, [start(ms),stop(ms)] baseline_window (s) before event\n",
    "    \"\"\"\n",
    "    preevent = [event[0] - (baseline_window*1000)-1, event[0]-1]\n",
    "    return np.array(preevent)\n",
    "\n",
    "\n",
    "def max_events(unit_dict, max_event, pre_window, timebin = 1):\n",
    "    \"\"\"\n",
    "    creates a dictionary with unit firing rates during events no longer\n",
    "    than max_event (s) (all longer events will be trimmed) and start times\n",
    "    adjusted to include pre_window time (s)\n",
    "\n",
    "    Args (4 total):\n",
    "        unit_dict: dict, unit id as keys, and values are spiketrains or firing rates \n",
    "        max_event: int, longest event length (s) returned (all longer events will be trimmed)\n",
    "        pre_window: int, amount of preevent time (s) returned\n",
    "        timebin: timebin (ms) of dict\n",
    "\n",
    "    Returns (1):\n",
    "        snippets_dict: dict, unit id as keys, values are spiketrains or firing rates during\n",
    "        pre_window and up until max event \n",
    "    \"\"\"\n",
    "    \n",
    "    snippets_dict = {}\n",
    "    for unit in unit_dict.keys():\n",
    "        events = unit_dict[unit]\n",
    "        try:\n",
    "            events = [event[0:int((pre_window + max_event)*1000/timebin)] for event in events]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        snippets_dict[unit] = events\n",
    "    return snippets_dict\n",
    "\n",
    "\n",
    "def get_unit_average_events(unit_event_snippets):\n",
    "    unit_average_event = {}\n",
    "    for unit in unit_event_snippets.keys():\n",
    "        unit_average_event[unit] = np.mean(unit_event_snippets[unit], axis=0)\n",
    "    return unit_average_event\n",
    "\n",
    "\n",
    "class EphysRecording:\n",
    "    \"\"\"\n",
    "    A class for an ephys recording after being spike sorted and manually curated using phy. \n",
    "    Ephys recording must have a phy folder. \n",
    "\n",
    "    Attributes:\n",
    "        path: str, relative path to the phy folder\n",
    "            formatted as: './folder/folder/phy'\n",
    "        subject: str, subject id who was being recorded\n",
    "        sampling_rate: int, sampling rate of the ephys device\n",
    "            in Hz, standard in the PC lab is 20,000Hz\n",
    "        timestamps_var: numpy array, all spike timestamps \n",
    "            of good and mua units (no noise unit-generated spikes)\n",
    "        unit_array: numpy array, unit ids associated with each\n",
    "            spike in the timestamps_var\n",
    "        labels_dict: dict, keys are unit ids (str) and\n",
    "            values are labels (str)\n",
    "        unit_timestamps: dict, keys are unit ids (int), and\n",
    "            values are numpy arrays of timestamps for all spikes \n",
    "            from \"good\" units only \n",
    "        spiketrain: np.array, spiketrain of number of spikes in a specified timebin\n",
    "        unit_spiketrains: dict, spiketrains for each unit\n",
    "            keys: str, unit ids\n",
    "            values: np.array, number of spikes per specified timebin\n",
    "        unit_firing_rates: dict, firing rates per unit\n",
    "            keys: str, unit ids\n",
    "            values: np.arrays, firing rate of unit in a specified timebin \n",
    "                    calculated with a specified smoothing window\n",
    "\n",
    "    Methods: (all called in __init__)\n",
    "        get_unit_labels: creates labels_dict\n",
    "        get_spike_specs: creates timestamps_var and unit_array\n",
    "        get_unit_timestamps: creates unit_timestamps dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path, sampling_rate=20000):\n",
    "        \"\"\"\n",
    "        constructs all necessary attributes for the EphysRecording object\n",
    "        including creating labels_dict, timestamps_var, and a unit_timstamps \n",
    "        dictionary \n",
    "        \n",
    "        Arguments (2 total):\n",
    "            path: str, relative path to the phy folder\n",
    "                formatted as: './folder/folder/phy'\n",
    "            sampling_rate: int, default=20000; sampling rate of \n",
    "                the ephys device in Hz\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.zscored_events = {}\n",
    "        self.wilcox_dfs = {}\n",
    "        self.get_unit_labels()\n",
    "        self.get_spike_specs()\n",
    "        self.get_unit_timestamps()\n",
    "\n",
    "    \n",
    "    def get_unit_labels(self):\n",
    "        \"\"\"\n",
    "        assigns self.labels_dicts as a dictionary \n",
    "        with unit id (str) as key and label as values (str)\n",
    "        labels: 'good', 'mua', 'noise' \n",
    "\n",
    "        Arguments:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        labels = 'cluster_group.tsv'\n",
    "        with open(os.path.join(self.path, labels), 'r') as f:\n",
    "            reader = csv.DictReader(f, delimiter='\\t')\n",
    "            self.labels_dict = {row['cluster_id']: row['group'] for row in reader}\n",
    "\n",
    "    \n",
    "    def get_spike_specs(self):\n",
    "        \"\"\"\n",
    "        imports spike_time and spike_unit from phy folder\n",
    "        deletes spikes from units labeled noise in unit and timestamp array\n",
    "        and assigns self.timstamps_var (numpy array) as the remaining timestamps \n",
    "        and assigns self.unit_array (numpy array) as the unit ids associated\n",
    "        with each spike\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            None \n",
    "        \"\"\"\n",
    "        timestamps = 'spike_times.npy'\n",
    "        unit = 'spike_clusters.npy'\n",
    "        timestamps_var = np.load(os.path.join(self.path, timestamps))\n",
    "        unit_array = np.load(os.path.join(self.path, unit))\n",
    "        spikes_to_delete = []\n",
    "        for spike in range(len(timestamps_var)): \n",
    "            if self.labels_dict[unit_array[spike].astype(str)] == 'noise':\n",
    "                spikes_to_delete.append(spike)\n",
    "        self.timestamps_var = np.delete(timestamps_var, spikes_to_delete)\n",
    "        self.unit_array = np.delete(unit_array, spikes_to_delete)\n",
    "\n",
    "    \n",
    "    def get_unit_timestamps(self):\n",
    "        \"\"\"\n",
    "        creates a dictionary of units to spike timestamps\n",
    "        keys are unit ids (int) and values are spike timestamps for that unit (numpy arrays)\n",
    "        and assigns dictionary to self.unit_timestamps\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "        \n",
    "        Return:\n",
    "            None\n",
    "        \"\"\"\n",
    "        \n",
    "        unit_timestamps = {}\n",
    "        for spike in range(len(self.timestamps_var)): \n",
    "            if self.unit_array[spike] in unit_timestamps.keys():\n",
    "                timestamp_list = unit_timestamps[self.unit_array[spike]] \n",
    "                timestamp_list = np.append(timestamp_list, self.timestamps_var[spike])\n",
    "                unit_timestamps[self.unit_array[spike]] = timestamp_list\n",
    "            else:\n",
    "                unit_timestamps[self.unit_array[spike]] = self.timestamps_var[spike]\n",
    "        \n",
    "        self.unit_timestamps = unit_timestamps   \n",
    "    \n",
    "\n",
    "class MultiEvents:\n",
    "    \"\"\"\n",
    "    A class for ephys statistics done on multiple event types\n",
    "    an EphysRecording class instance \n",
    "    and an event dictionary\n",
    "    where keys are event type names and values are arrays [[start (ms), stop(ms)]..]\n",
    "    \n",
    "\n",
    "    Attributes:\n",
    "        event_dict: dict, dictionary of event names and event start and stop times\n",
    "            key: str, name of the event \n",
    "            value: numpy array of [[start (ms), stop (ms)] x n events]\n",
    "        event_types: lst of strs, from the keys of the event dict\n",
    "        events: list of all start and stop times from event types \n",
    "        smoothing_window: int, default=250, window length in ms used to calculate firing rates\n",
    "        timebin: int, default=1, bin size (in ms) for spike train and firing rate arrays\n",
    "        ignore_freq: int, default=0, frequency in Hz that a good unit needs to fire at to be included in analysis\n",
    "        longest_event: int, length of longest event (ms)\n",
    "        event_lengths: lst, length of all events (ms)\n",
    "        spiketrain: numpy array, each element of the array \n",
    "            is the number of spikes per timebin throughout the whole recording\n",
    "        unit_spiketrains: dict, keys are unit ids (int), values (numpy arrays) are each \"good\"\n",
    "            units spiketrains in the specified timebins for the whole recording\n",
    "        unit_firing_rates: dict, keys are unit ids (int), values (numpy array) are each \"good\"\n",
    "            units firing rates calculated using smoothing_window in bins of size timebin\n",
    "\n",
    "    Methods: \n",
    "        get_whole_spiketrain: \n",
    "        get_unit_spiketrains: \n",
    "        get_unit_firing_rates: \n",
    "        get_event_snippets:\n",
    "        get_unit_event_firing_rates:\n",
    "        wilcox_baseline_v_event_stats:\n",
    "        wilcox_baseline_v_event_plots:\n",
    "    \"\"\"\n",
    "    def __init__(self, event_dict, recording, smoothing_window=250, timebin=1, ignore_freq=0.01):\n",
    "        \n",
    "        self.e_recording = recording\n",
    "        self.event_dict = event_dict\n",
    "        self.event_types = list(event_dict.keys())\n",
    "        self.events = [value for sublist in event_dict.values() for value in sublist]\n",
    "        self.smoothing_window = smoothing_window\n",
    "        self.timebin = timebin\n",
    "        self.ignore_freq = ignore_freq\n",
    "        self.longest_event, self.event_lengths, self.mean_event_length = get_event_lengths(self.events)\n",
    "        self.get_whole_spiketrain()\n",
    "        self.get_unit_spiketrains()\n",
    "        self.get_unit_firing_rates()\n",
    "\n",
    "    \n",
    "    def get_whole_spiketrain(self):\n",
    "        \"\"\"\n",
    "        creates a spiketrain of ms time bins \n",
    "        each array element is the number of spikes recorded per ms\n",
    "        \n",
    "        Args (1 total):\n",
    "            timestamp_array: numpy array, spike timestamp array\n",
    "            \n",
    "        Returns (1):\n",
    "            spiketrain_ms_timebins: a numpy array \n",
    "                array elements are number of spikes per ms \n",
    "        \"\"\"\n",
    "        if isinstance(self.recording, EphysRecording): \n",
    "            self.spiketrain = get_spiketrain(self.recording.timestamps_var, self.recording.sampling_rate, self.timebin)\n",
    "        else: \n",
    "            for recording in self.ephys_recording.collection.values():\n",
    "                recording.spiketrain = get_spiketrain(recording.timestamps_var, recording.sampling_rate, self.timebin)\n",
    "    \n",
    "    def get_unit_spiketrains(self):  \n",
    "        \"\"\"\n",
    "        Creates a dictionary and assigns it as self.unit_spiketrains\n",
    "        where keys are 'good' unit ids (int) (not 'mua') that reach\n",
    "        a threshold frequency, values are numpy arrays of \n",
    "        spiketrains in timebin sized bins\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "            \n",
    "        Reutrns:\n",
    "            None\n",
    "            \n",
    "        \"\"\"\n",
    "        if isinstance(self.recording, EphysRecording): \n",
    "            unit_spiketrains = {}\n",
    "            for unit in self.recording.unit_timestamps.keys():\n",
    "                if self.recording.labels_dict[str(unit)] == 'good':\n",
    "                    no_spikes = len(self.recording.unit_timestamps[unit])\n",
    "                    unit_freq = no_spikes/self.recording.timestamps_var[-1]*self.recording.sampling_rate\n",
    "                    if unit_freq > self.ignore_freq:\n",
    "                        unit_spiketrains[unit] = get_spiketrain(self.recording.unit_timestamps[unit], \n",
    "                                                                self.recording.sampling_rate, self.timebin)\n",
    "            self.unit_spiketrains = unit_spiketrains\n",
    "        else:\n",
    "            for recording in self.ephys_recording.collection.values():\n",
    "                unit_spiketrains = {}\n",
    "                for unit in self.recording.unit_timestamps.keys():\n",
    "                    if self.recording.labels_dict[str(unit)] == 'good':\n",
    "                        no_spikes = len(self.recording.unit_timestamps[unit])\n",
    "                        unit_freq = no_spikes/self.recording.timestamps_var[-1]*self.recording.sampling_rate\n",
    "                        if unit_freq > self.ignore_freq:\n",
    "                            unit_spiketrains[unit] = get_spiketrain(self.recording.unit_timestamps[unit], \n",
    "                                                                    self.recording.sampling_rate, self.timebin)\n",
    "                recording.unit_spiketrains = unit_spiketrains    \n",
    "\n",
    "    \n",
    "    def get_unit_firing_rates(self):  \n",
    "        \"\"\"\n",
    "        Calculates firing rates per unit,\n",
    "        creates a dictionary and assigns it as self.unit_firing_rates\n",
    "        the keys are unit ids (int) and values are firing rates for the\n",
    "        unit (numpy array) in timebin sized bins \n",
    "        calculated using smoothing_window for averaging\n",
    "        \n",
    "        Args:\n",
    "            none\n",
    "            \n",
    "        Returns:\n",
    "            none\n",
    "        \"\"\"\n",
    "        if isinstance(self.recording, EphysRecording): \n",
    "            unit_firing_rates = {}\n",
    "            for unit in self.unit_spiketrains.keys():\n",
    "                unit_firing_rates[unit] = get_firing_rate(self.unit_spiketrains[unit], self.smoothing_window, self.timebin)\n",
    "            self.unit_firing_rates = unit_firing_rates\n",
    "\n",
    "        else:\n",
    "            for recording in self.ephys_recording.collection.values():\n",
    "                unit_firing_rates = {}\n",
    "                for unit in self.unit_spiketrains.keys():\n",
    "                    unit_firing_rates[unit] = get_firing_rate(self.unit_spiketrains[unit], self.smoothing_window, self.timebin)\n",
    "                recording.unit_firing_rates = unit_firing_rates\n",
    "    \n",
    "    def get_event_snippets(self, event, whole_recording, equalize, pre_window=0, post_window=0):\n",
    "        \"\"\"\n",
    "        takes snippets of spiketrains or firing rates for events\n",
    "        optional pre-event and post-event windows (s) may be included\n",
    "        all events can also be of equal length by extending \n",
    "        snippet lengths to the longest event\n",
    "    \n",
    "        Args (5 total, 1 required): \n",
    "            whole_recording: numpy array, spiketrain or firing rates \n",
    "                for the whole recording, for population or for a single unit\n",
    "            pre_window: int, default=0, seconds prior to start of event returned\n",
    "            post_window: int, default=0, seconds after end of event returned\n",
    "            equalize: {user_defined, 'max', 'average'}, equalizes lengths of events\n",
    "                by padding with post event time or trimming event\n",
    "                user_defined: float, makes all events user_defined (s) long   \n",
    "                'max': makes all events as long as the longest event \n",
    "                'average': makes all events as long as the average event length \n",
    "            events:numpy array of [[start (ms), stop (ms)] x n events], \n",
    "                default=None in which case self.events is used\n",
    "    \n",
    "        Returns (1):\n",
    "            event_snippets: a list of lists, where each list is a list of firing rates\n",
    "                or spiketrains during an event including pre_window&post_windows, \n",
    "                accounting for equalize and timebins\n",
    "        \"\"\"\n",
    "        \n",
    "        if event in self.event_dict.keys():\n",
    "            events = self.event_dict[event]\n",
    "        event_snippets = []\n",
    "        pre_window = math.ceil(pre_window*1000)\n",
    "        post_window = math.ceil(post_window*1000)\n",
    "        for i in range(events.shape[0]):\n",
    "            if equalize == 'max':\n",
    "                event_diff = math.ceil(self.longest_event - self.event_lengths[i])\n",
    "            if equalize == 'average':\n",
    "                event_diff = math.ceil(self.mean_event_length - self.event_lengths[i])\n",
    "            else:\n",
    "                event_diff = math.ceil(equalize*1000 - self.event_lengths[i])\n",
    "            pre_event = math.ceil((events[i][0] - pre_window)/self.timebin)\n",
    "            post_event = math.ceil((events[i][1] + post_window + event_diff)/self.timebin)\n",
    "            event_snippet = whole_recording[pre_event:post_event]\n",
    "            event_snippets.append(event_snippet)\n",
    "        return event_snippets\n",
    "    \n",
    "    def get_unit_event_firing_rates(self, event, equalize, pre_window = 0, post_window = 0, e_collection = False):\n",
    "        \"\"\"\n",
    "        returns firing rates for events per unit\n",
    "    \n",
    "        Args (6 total, 1 required):\n",
    "            smoothing_window: int, default=250, smoothing average window (ms)\n",
    "                min smoothing_window = 1 \n",
    "            timebin: int, default 1, timebin in ms for firing rate array\n",
    "            pre_window: int, default=0, seconds prior to start of event returned\n",
    "            post_window: int, default=0, seconds after end of event returned\n",
    "            equalize: {'max', average'}, default=False, equalizes lengths of events\n",
    "                by padding with post event time or trimming event\n",
    "                'max': makes all events as long as the longest event \n",
    "                'average': makes all events as long as the average event length \n",
    "            events:numpy array of [[start (ms), stop (ms)] x n events], \n",
    "                default=None in which case self.events is used\n",
    "            \n",
    "        Return (1):\n",
    "            unit_event_firing_rates: dict, keys are unit ids (???),\n",
    "            values are lsts of numpy arrays of firing rates per event\n",
    "        \"\"\"\n",
    "        if not e_collection: \n",
    "            unit_event_firing_rates = {}\n",
    "            for unit in self.unit_spiketrains.keys():\n",
    "                unit_event_firing_rates[unit] = self.get_event_snippets(event, self.unit_firing_rates[unit], equalize, pre_window, post_window)\n",
    "            return unit_event_firing_rates\n",
    "        else:\n",
    "            unit_event_firing_rates = {}\n",
    "            for unit in self.unit_spiketrains.keys():\n",
    "                unit_event_firing_rates[unit] = self.get_event_snippets(event, e_collection.unit_firing_rates[unit], equalize, pre_window, post_window)\n",
    "            return unit_event_firing_rates\n",
    "        \n",
    "    def wilcox_baseline_v_event_stats(self, event, baseline_window, equalize):\n",
    "        #what if i wanted a random snippet from the first ten minutes instead of prior to the event?\n",
    "        \"\"\"\n",
    "        calculates wilcoxon signed-rank test for average firing rates of two windows: event vs baseline\n",
    "        baseline used is an amount of time immediately prior to the event\n",
    "        wilcoxon signed-rank test is applied to two sets of measurements:\n",
    "        average firing rate per event, average firing rate per baseline\n",
    "        \n",
    "        Args (3 total, 1 required):\n",
    "            baseline_window: int, length of baseline firing rate (s)\n",
    "            max_event: int, default=None, max length of an event (s)\n",
    "            equalize: Boolean, default=False, if True, equalizes lengths of each event to longest event\n",
    "    \n",
    "        Return (1):\n",
    "            wilcoxon_df: pandas dataframe, columns are unit ids, \n",
    "            row[0] are wilcoxon statistics and row[1] are p values \n",
    "        \n",
    "        \"\"\"\n",
    "        preevent_baselines = np.array([pre_event_window(event, baseline_window) for event in self.event_dict[event]])\n",
    "        unit_preevent_firing_rates = self.get_unit_event_firing_rates(preevent_baselines, baseline_window, 0, 0)\n",
    "        unit_event_firing_rates = self.get_unit_event_firing_rates(equalize,0,0)\n",
    "        if equalize == 'average':\n",
    "            self.wilcox_xstop = self.mean_event_length\n",
    "        if equalize == 'max':\n",
    "            self.wilcox_xstop = self.longest_event\n",
    "        else:\n",
    "            self.wilcox_xstop = equalize*1000\n",
    "        unit_averages = {}\n",
    "        for unit in unit_event_firing_rates.keys():\n",
    "            try:\n",
    "                event_averages = [mean(event) for event in unit_event_firing_rates[unit]]\n",
    "                preevent_averages = [mean(event) for event in unit_preevent_firing_rates[unit]]\n",
    "                unit_averages[unit] = [event_averages, preevent_averages]\n",
    "            except:\n",
    "                print(f'Unit {unit} has {len(self.recording.unit_timestamps[unit])} spikes')\n",
    "        wilcoxon_stats = {}\n",
    "        for unit in unit_averages.keys(): \n",
    "            wilcoxon_stats[unit] = wilcoxon(unit_averages[unit][0], unit_averages[unit][1], method = 'approx')\n",
    "        wilcoxon_df = pd.DataFrame.from_dict(wilcoxon_stats)\n",
    "        wilcoxon_df.index = ['Wilcoxon Stat', 'p value']\n",
    "        self.wilcox_baseline = baseline_window\n",
    "        return wilcoxon_df\n",
    "\n",
    "    def fishers_exact_wilcox(self, baseline_window, equalize):\n",
    "        sig_units = {}\n",
    "        for event in self.event_dict.keys():\n",
    "            wilcox_df = self.wilcox_baseline_v_event_stats(event, baseline_window, equalize) \n",
    "            sig_units[event] = (len(wilcox_df[(wilcox_df[1]<=0.05)]), len(wilcox_df[(wilcox_df[1]>.05)])) \n",
    "        fishers_df = pd.DataFrame(sig_units.values(), index=sig_units.keys(), columns=['Significant', 'Not Significant'])\n",
    "\n",
    "                        \n",
    "\n",
    "    def wilcox_baseline_v_event_plots(self, title, p_value=None, units=None):\n",
    "        \"\"\"\n",
    "        plots event triggered average firing rates for units\n",
    "        all events need to be the same length\n",
    "\n",
    "        Args(3 total, 1 required):\n",
    "            title: str, title of figure\n",
    "            p_value: int, default=None, all p values less than will be plotted\n",
    "            units: lst, default=None, list of unit ids (ints) to be plotted\n",
    "\n",
    "        Returns:\n",
    "            none\n",
    "        \"\"\" \n",
    "        units_to_plot = []\n",
    "        if p_value is not None:\n",
    "            for unit in self.wilcoxon_df.columns.tolist():\n",
    "                if self.wilcoxon_df[unit][1] < p_value:\n",
    "                      units_to_plot.append(unit)\n",
    "        else:\n",
    "            if units is None:\n",
    "                units_to_plot = self.wilcoxon_df.columns.tolist()\n",
    "            else:\n",
    "                units_to_plot = units\n",
    "        no_plots = len(units_to_plot)\n",
    "        height_fig = math.ceil(no_plots/3)\n",
    "        i = 1\n",
    "        plt.figure(figsize=(20,4*height_fig))\n",
    "        unit_event_firing_rates = self.get_unit_event_firing_rates(self.wilcox_baseline, 0, True)\n",
    "        x_stop = self.wilcox_xstop\n",
    "        for unit in units_to_plot:\n",
    "            mean_arr = np.mean(unit_event_firing_rates[unit], axis=0)\n",
    "            sem_arr = sem(unit_event_firing_rates[unit], axis=0)\n",
    "            p_value = self.wilcoxon_df[unit][1]\n",
    "            x = np.linspace(start=-self.wilcox_baseline,stop=x_stop,num=len(mean_arr))\n",
    "            plt.subplot(height_fig,3,i)\n",
    "            plt.plot(x, mean_arr, c= 'b')\n",
    "            plt.axvline(x=0, color='r', linestyle='--')\n",
    "            plt.fill_between(x, mean_arr-sem_arr, mean_arr+sem_arr, alpha=0.2)\n",
    "            plt.title(f'Unit {unit} Average (p={p_value})')\n",
    "            i+=1\n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "\n",
    "    def wilcoxon_event_v_event_stats(self, event1, event2, equalize):\n",
    "        \"\"\"\n",
    "        calculates wilcoxon signed-rank test for average firing rates of two windows: event vs baseline\n",
    "        baseline used is an amount of time immediately prior to the event\n",
    "        wilcoxon signed-rank test is applied to two sets of measurements:\n",
    "        average firing rate per event, average firing rate per baseline\n",
    "        \n",
    "        Args (3 total, 1 required):\n",
    "            baseline_window: int, length of baseline firing rate (s)\n",
    "            max_event: int, default=None, max length of an event (s)\n",
    "            equalize: {'max', average'}, default=False, equalizes lengths of events\n",
    "                by padding with post event time or trimming event\n",
    "                'max': makes all events as long as the longest event \n",
    "                'average': makes all events as long as the average event length \n",
    "    \n",
    "        Return (1):\n",
    "            wilcoxon_df: pandas dataframe, columns are unit ids, \n",
    "            row[0] are wilcoxon statistics and row[1] are p values \n",
    "        \n",
    "        \"\"\"\n",
    "        unit_event1_firing_rates = self.get_unit_event_firing_rates(event1, equalize, 0, 0)\n",
    "        unit_event2_firing_rates = self.get_unit_event_firing_rates(event2, equalize, 0, 0)\n",
    "        unit_averages = {}\n",
    "        for unit in unit_event1_firing_rates.keys():\n",
    "            try:\n",
    "                event1_averages = [mean(event) for event in unit_event1_firing_rates[unit]]\n",
    "                event2_averages = [mean(event) for event in unit_event2_firing_rates[unit]]\n",
    "                unit_averages[unit] = [event1_averages, event2_averages]\n",
    "            except:\n",
    "                print(f'Unit {unit} has {len(self.recording.unit_timestamps[unit])} spikes')\n",
    "        wilcoxon_stats = {}\n",
    "        for unit in unit_averages.keys(): \n",
    "            wilcoxon_stats[unit] = wilcoxon(unit_averages[unit][0], unit_averages[unit][1], method = 'approx')\n",
    "        wilcoxon_df = pd.DataFrame.from_dict(wilcoxon_stats)\n",
    "        self.wilcoxon_df = wilcoxon_df\n",
    "\n",
    "    def get_zscore(self, event, baseline_window, equalize):\n",
    "        #nancy had a matrix of (neuron, timebin, trial)\n",
    "        event = self.event_dict[event]\n",
    "        preevent_baselines = np.array([pre_event_window(event, baseline_window) for event in self.event])\n",
    "        unit_event_firing_rates = self.get_unit_event_firing_rates( baseline_window, 0, equalize)\n",
    "        unit_preevent_firing_rates = self.get_unit_event_firing_rates(0,0,False,preevent_baselines)\n",
    "        zscored_events = {}\n",
    "        for unit in unit_event_firing_rates:\n",
    "            #calculate average event across all events per unit\n",
    "            event_average = np.mean(unit_event_firing_rates[unit], axis = 0)\n",
    "            #one average for all preevents \n",
    "            preevent_average = np.mean(unit_preevent_firing_rates[unit], axis = 0)\n",
    "            mew = np.mean(preevent_average)\n",
    "            sigma = np.std(preevent_average)\n",
    "            zscored_event = [(event_bin - mew)/sigma for event_bin in event_average]\n",
    "            zscored_events[unit] = zscored_event\n",
    "        self.zscored_events = zscored_events\n",
    "        self.zscore_baseline = baseline_window\n",
    "        if equalize == 'average':\n",
    "            self.zscore_xstop = self.mean_event_length\n",
    "        if equalize == 'max':\n",
    "            self.zscore_xstop = self.longest_event\n",
    "        else:\n",
    "            self.zscore_xstop = equalize*1000\n",
    "        \n",
    "    def get_zcore_plot(self, max_event, title):\n",
    "        plt.figure(figsize=(20,6))\n",
    "        baseline_window = self.zscore_baseline\n",
    "        zscored_unit_event_firing_rates = self.zscored_events\n",
    "        zscore_pop = np.array(list(zscored_unit_event_firing_rates.values()))\n",
    "        mean_arr = np.mean(zscore_pop, axis=0)\n",
    "        sem_arr = sem(zscore_pop, axis=0)\n",
    "        x = np.linspace(start=-baseline_window,stop=self.zscore_xstop,num=len(mean_arr))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(x, mean_arr, c= 'b')\n",
    "        plt.axvline(x=0, color='r', linestyle='--')\n",
    "        plt.fill_between(x, mean_arr-sem_arr, mean_arr+sem_arr, alpha=0.2)\n",
    "        plt.title(f'Population z-score {self.event} event')\n",
    "        plt.subplot(1,2,2)\n",
    "        for unit in zscored_unit_event_firing_rates.keys():\n",
    "            plt.plot(x, zscored_unit_event_firing_rates[unit], linewidth = .5)\n",
    "            plt.axvline(x=0, color='r', linestyle='--')\n",
    "            plt.title(f'Unit z-score {self.event} event')\n",
    "        plt.suptitle(f'{title} Z-scored average {self.event} event')\n",
    "        plt.show()        \n",
    "\n",
    "    def PCA_trajectories(self, pre_window = 0, post_window = 0, equalize = 'average'):\n",
    "        first_event = True\n",
    "        for event in self.event_dict.keys():\n",
    "            unit_event_firing_rates = self.get_unit_event_firing_rates(self, event, pre_window, post_window, equalize)\n",
    "            unit_event_average = get_unit_average_events(unit_event_firing_rates) \n",
    "            if first_event:\n",
    "                PCA_matrix = [value for sublist in unit_event_average.values() for value in sublist]\n",
    "                PCA_key = [event] * len(PCA_matrix)\n",
    "                first_event = False\n",
    "            else:\n",
    "                next_event = [value for sublist in unit_event_average.values() for value in sublist]\n",
    "                PCA_matrix = np.concatenate([PCA_matrix, next_event], axis=0)\n",
    "                next_event_key = [event] * len(next_event)\n",
    "                PCA_key = PCA_key + next_event_key\n",
    "        pca = PCA(n_components = 2)\n",
    "        transformed_matrix = pca.fit_transform(PCA_matrix)\n",
    "        self.PCA_trajectories = transformed_matrix\n",
    "        self.PCA_key = PCA_key\n",
    "\n",
    "class EphysRecordingCollection:\n",
    "    #this should have an event dictionary baked into it as well as subject per recording\n",
    "    #and an initiated\n",
    "    def __init__(self, path, sampling_rate=20000):\n",
    "\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.path = path \n",
    "        self.wilcox_dfs = {}\n",
    "        self.zscored_events = {}\n",
    "        self.make_collection()\n",
    "\n",
    "    def make_collection(self):\n",
    "        \n",
    "        collection = {}\n",
    "        for root, dirs, files in os.walk(self.path):\n",
    "            for directory in dirs:\n",
    "                if directory.endswith('merged.rec'):\n",
    "                    tempobject = EphysRecording(os.path.join(self.path, directory, 'phy'), self.sampling_rate)\n",
    "                    collection[directory] = tempobject\n",
    "        self.collection = collection\n",
    "\n",
    "\n",
    "    def get_by_name(self, name):\n",
    "        return self.collection[name] \n",
    "\n",
    "    def assign_events(self):\n",
    "        for root, dirs, files in os.walk(self.path):\n",
    "            for directory in dirs:\n",
    "                if directory.endswith('merged.rec'):\n",
    "                    reader = csv.DictReader(f, delimter='\\t')\n",
    "                    self.collection[directory].event_dict = {row['event']: row['start&stop'] for row in reader}\n",
    "\n",
    "    \n",
    "\n",
    "class MultiEvent_MultiSession:\n",
    "    \"\"\"\n",
    "    A class for ephys statistics done on multiple event types for multiple recordings\n",
    "\n",
    "    where keys are event type names and values are arrays [[start (ms), stop(ms)]..]\n",
    "    \n",
    "\n",
    "    Attributes:\n",
    "        event_dict: dict, dictionary of event names and event start and stop times\n",
    "            key: str, name of the event \n",
    "            value: numpy array of [[start (ms), stop (ms)] x n events]\n",
    "        event_types: lst of strs, from the keys of the event dict\n",
    "        events: list of all start and stop times from event types \n",
    "        smoothing_window: int, default=250, window length in ms used to calculate firing rates\n",
    "        timebin: int, default=1, bin size (in ms) for spike train and firing rate arrays\n",
    "        ignore_freq: int, default=0, frequency in Hz that a good unit needs to fire at to be included in analysis\n",
    "        longest_event: int, length of longest event (ms)\n",
    "        event_lengths: lst, length of all events (ms)\n",
    "        spiketrain: numpy array, each element of the array \n",
    "            is the number of spikes per timebin throughout the whole recording\n",
    "        unit_spiketrains: dict, keys are unit ids (int), values (numpy arrays) are each \"good\"\n",
    "            units spiketrains in the specified timebins for the whole recording\n",
    "        unit_firing_rates: dict, keys are unit ids (int), values (numpy array) are each \"good\"\n",
    "            units firing rates calculated using smoothing_window in bins of size timebin\n",
    "\n",
    "    Methods: \n",
    "        get_whole_spiketrain: \n",
    "        get_unit_spiketrains: \n",
    "        get_unit_firing_rates: \n",
    "        get_event_snippets:\n",
    "        get_unit_event_firing_rates:\n",
    "        wilcox_baseline_v_event_stats:\n",
    "        wilcox_baseline_v_event_plots:\n",
    "    \"\"\"\n",
    "    def __init__(self, collection, smoothing_window=250, timebin=1, ignore_freq=0.01):\n",
    "        #each recording within the collection should have its own event dictionary as an attribute\n",
    "        \n",
    "        self.collection = collection\n",
    "        self.event_dict = event_dict\n",
    "        self.event_types = list(event_dict.keys())\n",
    "        self.events = [value for sublist in event_dict.values() for value in sublist]\n",
    "        self.smoothing_window = smoothing_window\n",
    "        self.timebin = timebin\n",
    "        self.ignore_freq = ignore_freq\n",
    "        self.longest_event, self.event_lengths, self.mean_event_length = get_event_lengths(self.events)\n",
    "        self.get_whole_spiketrain()\n",
    "        self.get_unit_spiketrains()\n",
    "        self.get_unit_firing_rates()\n",
    "\n",
    "    \n",
    "    def get_whole_spiketrain(self):\n",
    "        \"\"\"\n",
    "        creates a spiketrain with timebin length timebins \n",
    "        for each recording in the collection\n",
    "        each array element is the number of spikes per timebin\n",
    "\n",
    "        each spiketrian is assigned as an attribute for that recording\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "         \n",
    "        \"\"\"\n",
    "        for recording in self.collection.values():\n",
    "            recording.spiketrain = get_spiketrain(recording.timestamps_var, recording.sampling_rate, self.timebin)\n",
    "    \n",
    "    def get_unit_spiketrains(self):  \n",
    "        \"\"\"\n",
    "        Creates a dictionary and assigns it as recording.unit_spiketrains\n",
    "        for each recording in the collection\n",
    "        where keys are 'good' unit ids (int) (not 'mua') that reach\n",
    "        a threshold frequency, values are numpy arrays of \n",
    "        spiketrains in timebin sized bins\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "            \n",
    "        Reutrns:\n",
    "            None\n",
    "            \n",
    "        \"\"\"\n",
    "        sampling_rate = self.collection.sampling_rate\n",
    "        for recording in self.collection.values():\n",
    "                unit_spiketrains = {}\n",
    "                for unit in recording.unit_timestamps.keys():\n",
    "                    if recording.labels_dict[str(unit)] == 'good':\n",
    "                        no_spikes = len(recording.unit_timestamps[unit])\n",
    "                        unit_freq = no_spikes/recording.timestamps_var[-1]*sampling_rate\n",
    "                        if unit_freq > self.ignore_freq:\n",
    "                            unit_spiketrains[unit] = get_spiketrain(recording.unit_timestamps[unit], \n",
    "                                                                    sampling_rate, \n",
    "                                                                    self.timebin)\n",
    "                recording.unit_spiketrains = unit_spiketrains    \n",
    "    \n",
    "    def get_unit_firing_rates(self):  \n",
    "        \"\"\"\n",
    "        Calculates firing rates per unit per recording in collection,\n",
    "        creates a dictionary and assigns it as recording.unit_firing_rates\n",
    "        the keys are unit ids (int) and values are firing rates for the\n",
    "        unit (numpy array) in timebin sized bins \n",
    "        calculated using smoothing_window for averaging\n",
    "        \n",
    "        Args:\n",
    "            none\n",
    "            \n",
    "        Returns:\n",
    "            none\n",
    "        \"\"\"\n",
    "        for recording in self.collection.values():\n",
    "            unit_firing_rates = {}\n",
    "            for unit in recording.unit_spiketrains.keys():\n",
    "                unit_firing_rates[unit] = get_firing_rate(recording.unit_spiketrains[unit],\n",
    "                                                        self.smoothing_window, \n",
    "                                                        self.timebin)\n",
    "            recording.unit_firing_rates = unit_firing_rates\n",
    "    \n",
    "    def get_event_snippets(self, recording, event, whole_recording, equalize, pre_window=0, post_window=0):\n",
    "        \"\"\"\n",
    "        takes snippets of spiketrains or firing rates for events\n",
    "        optional pre-event and post-event windows (s) may be included\n",
    "        all events can also be of equal length by extending \n",
    "        snippet lengths to the longest event\n",
    "    \n",
    "        Args (5 total, 1 required): \n",
    "            whole_recording: numpy array, spiketrain or firing rates \n",
    "                for the whole recording, for population or for a single unit\n",
    "            pre_window: int, default=0, seconds prior to start of event returned\n",
    "            post_window: int, default=0, seconds after end of event returned\n",
    "            equalize: {user_defined(float), 'max', 'average'}, equalizes lengths of events\n",
    "                by padding with post event time or trimming event\n",
    "                user_defined: float, makes all events user_defined (s) long   \n",
    "                'max': makes all events as long as the longest event \n",
    "                'average': makes all events as long as the average event length \n",
    "            events:numpy array of [[start (ms), stop (ms)] x n events], \n",
    "                default=None in which case self.events is used\n",
    "    \n",
    "        Returns (1):\n",
    "            event_snippets: a list of lists, where each list is a list of firing rates\n",
    "                or spiketrains during an event including pre_window&post_windows, \n",
    "                accounting for equalize and timebins\n",
    "        \"\"\"\n",
    "        #need to figure out how event lengths are going to work for max and average etc. \n",
    "        #or honestly maybe just get rid of the options \n",
    "        events = recording.event_dict[event]\n",
    "        event_snippets = []\n",
    "        pre_window = math.ceil(pre_window*1000)\n",
    "        post_window = math.ceil(post_window*1000)\n",
    "        for i in range(events.shape[0]):\n",
    "            if equalize == 'max':\n",
    "                event_diff = math.ceil(self.longest_event - self.event_lengths[i])\n",
    "            if equalize == 'average':\n",
    "                event_diff = math.ceil(self.mean_event_length - self.event_lengths[i])\n",
    "            else:\n",
    "                event_diff = math.ceil(equalize*1000 - self.event_lengths[i])\n",
    "            pre_event = math.ceil((events[i][0] - pre_window)/self.timebin)\n",
    "            post_event = math.ceil((events[i][1] + post_window + event_diff)/self.timebin)\n",
    "            event_snippet = whole_recording[pre_event:post_event]\n",
    "            event_snippets.append(event_snippet)\n",
    "        return event_snippets\n",
    "    \n",
    "    def get_unit_event_firing_rates(self, recording, event, equalize, pre_window = 0, post_window = 0):\n",
    "        \"\"\"\n",
    "        returns firing rates for events per unit\n",
    "    \n",
    "        Args (6 total, 1 required):\n",
    "            smoothing_window: int, default=250, smoothing average window (ms)\n",
    "                min smoothing_window = 1 \n",
    "            timebin: int, default 1, timebin in ms for firing rate array\n",
    "            pre_window: int, default=0, seconds prior to start of event returned\n",
    "            post_window: int, default=0, seconds after end of event returned\n",
    "            equalize: {user_defined(float), 'max', 'average'}, equalizes lengths of events\n",
    "                by padding with post event time or trimming event\n",
    "                user_defined: float, makes all events user_defined (s) long   \n",
    "                'max': makes all events as long as the longest event \n",
    "                'average': makes all events as long as the average event length  \n",
    "            events:numpy array of [[start (ms), stop (ms)] x n events], \n",
    "                default=None in which case self.events is used\n",
    "            \n",
    "        Return (1):\n",
    "            unit_event_firing_rates: dict, keys are unit ids (???),\n",
    "            values are lsts of numpy arrays of firing rates per event\n",
    "        \"\"\"\n",
    "        unit_event_firing_rates = {}\n",
    "        for unit in recording.unit_firing_rates.keys():\n",
    "            unit_event_firing_rates[unit] = self.get_event_snippets(recording, recording.event, recording.unit_firing_rates[unit], equalize, pre_window, post_window)\n",
    "        return unit_event_firing_rates\n",
    "    \n",
    "    def wilcox_baseline_v_event_stats(self, recording, event, baseline_window, equalize):\n",
    "        \"\"\"\n",
    "        calculates wilcoxon signed-rank test for average firing rates of two windows: event vs baseline\n",
    "        baseline used is an amount of time immediately prior to the event\n",
    "        wilcoxon signed-rank test is applied to two sets of measurements:\n",
    "        average firing rate per event, average firing rate per baseline.\n",
    "        the resulting dataframe of wilcoxon stats and p values for every unit \n",
    "        is added to a dictionary of dataframes for that recording. \n",
    "\n",
    "        Key for this dictionary item is '{event} vs {baselinewindow}second baseline' \n",
    "        and the value is the dataframe. \n",
    "        \n",
    "        Args (3 total, 1 required):\n",
    "            baseline_window: int, length of baseline firing rate (s)\n",
    "            max_event: int, default=None, max length of an event (s)\n",
    "            equalize: {user_defined(float), 'max', 'average'}, equalizes lengths of events\n",
    "                by padding with post event time or trimming event\n",
    "                user_defined: float, makes all events user_defined (s) long   \n",
    "                'max': makes all events as long as the longest event \n",
    "                'average': makes all events as long as the average event length\n",
    "    \n",
    "        Return (1):\n",
    "            wilcoxon_df: pandas dataframe, columns are unit ids, \n",
    "            row[0] are wilcoxon statistics and row[1] are p values \n",
    "        \n",
    "        \"\"\"\n",
    "        #this is another one where i gotta figure out/edit the equalize fxn\n",
    "        preevent_baselines = np.array([pre_event_window(event, baseline_window) for event in recording.event_dict[event]])\n",
    "        unit_preevent_firing_rates = self.get_unit_event_firing_rates(recording, preevent_baselines, baseline_window, 0, 0)\n",
    "        unit_event_firing_rates = self.get_unit_event_firing_rates(recording, event, equalize, 0, 0)\n",
    "        if equalize == 'average':\n",
    "            recording.wilcox_xstop = self.mean_event_length\n",
    "        if equalize == 'max':\n",
    "            recording.wilcox_xstop = self.longest_event\n",
    "        else:\n",
    "            recording.wilcox_xstop = equalize*1000\n",
    "        unit_averages = {}\n",
    "        for unit in unit_event_firing_rates.keys():\n",
    "            try:\n",
    "                event_averages = [mean(event) for event in unit_event_firing_rates[unit]]\n",
    "                preevent_averages = [mean(event) for event in unit_preevent_firing_rates[unit]]\n",
    "                unit_averages[unit] = [event_averages, preevent_averages]\n",
    "            except:\n",
    "                print(f'Unit {unit} has {len(recording.unit_timestamps[unit])} spikes')\n",
    "        wilcoxon_stats = {}\n",
    "        for unit in unit_averages.keys(): \n",
    "            wilcoxon_stats[unit] = wilcoxon(unit_averages[unit][0], unit_averages[unit][1], method = 'approx')\n",
    "        wilcoxon_df = pd.DataFrame.from_dict(wilcoxon_stats)\n",
    "        wilcoxon_df.index = ['Wilcoxon Stat', 'p value']\n",
    "        wilcox_key = f'{event} vs {baseline_window}second baseline'\n",
    "        recording.wilcox_dfs[wilcox_key] = wilcoxon_df\n",
    "        \n",
    "        return wilcoxon_df\n",
    "\n",
    "    # def fishers_exact_wilcox(self, baseline_window, equalize):\n",
    "    #     sig_units = {}\n",
    "    #     for event in self.event_dict.keys():\n",
    "    #         wilcox_df = self.wilcox_baseline_v_event_stats(event, baseline_window, equalize) \n",
    "    #         sig_units[event] = (len(wilcox_df[(wilcox_df[1]<=0.05)]), len(wilcox_df[(wilcox_df[1]>.05)])) \n",
    "    #     fishers_df = pd.DataFrame(sig_units.values(), index=sig_units.keys(), columns=['Significant', 'Not Significant'])\n",
    "\n",
    "    def wilcox_baseline_v_event_collection(self, event, baseline_window, equalize):  \n",
    "        #and another for equalize \n",
    "        \"\"\"\n",
    "        Runs a wilcoxon signed rank test on all good units of \n",
    "        all recordings in the collection on the \n",
    "        given event's firing rate versus the given baseline window.\n",
    "        Baseline window is the amount of time immediately prior to the event\n",
    "        whose firing rate is being compared. \n",
    "\n",
    "        Creates a dataframe with rows for each unit and columns representing \n",
    "        Wilcoxon stats, p values, orginal unit ids, recording,\n",
    "        subject and the event + baselien given. Dataframe is saved in the collections\n",
    "        wilcox_dfs dictionary, key is '{event} vs {baseline_window}second baseline'\n",
    "\n",
    "        Args(3 total):\n",
    "            event: str, event firing rates for stats to be run on \n",
    "            baseline_window: float, time (s) prior to event for stats to be run on\n",
    "            equalize: {user_defined(float), 'max', 'average'}, equalizes lengths of events\n",
    "                by padding with post event time or trimming event\n",
    "                user_defined: float, makes all events user_defined (s) long   \n",
    "                'max': makes all events as long as the longest event \n",
    "                'average': makes all events as long as the average event length\n",
    "        \"\"\"\n",
    "        is_first = True\n",
    "        for recording_name, recording in self.collection.item():\n",
    "            recording_df = self.wilcox_baseline_v_event_stats(self, recording, event, baseline_window, equalize)\n",
    "            recording_df = recording_df.transpose().reset_index()\n",
    "            recording_df = recording_df.rename(column={'index': 'original unit id'})\n",
    "            recording_df['Recording'] = recording_name\n",
    "            recording_df['Subject'] = recording.subject\n",
    "            recording_df['Event'] = [event, baseline_window] \n",
    "            if is_first:\n",
    "                master_df = recording_df\n",
    "                is_first = False\n",
    "            else:\n",
    "                master_df = pd.concat([master_df, recording_df], axis=0).reset_index(drop=True)\n",
    "        wilcox_key = f'{event} vs {baseline_window}second baseline'\n",
    "        self.collection.wilcox_dfs[wilcox_key] = master_df\n",
    "        return master_df\n",
    "\n",
    "\n",
    "\n",
    "    def wilcox_baseline_v_event_plots(self, recording, wilcoxon_df, event, equalize, baseline, title, p_value=None, units=None):\n",
    "        #ugh these plot functions are getting ugly \n",
    "        \"\"\"\n",
    "        plots event triggered average firing rates for units of a given recording. \n",
    "        optional filtering for p value threshold and unit ids. \n",
    "\n",
    "        Args(4 total, 2 required):\n",
    "            recording: an EphysRecording instance\n",
    "            title: str, title of figure\n",
    "            p_value: int, default=None, all p values less than will be plotted\n",
    "            units: lst, default=None, list of unit ids (ints) to be plotted\n",
    "\n",
    "        Returns:\n",
    "            none\n",
    "        \"\"\" \n",
    "        units_to_plot = []\n",
    "        if p_value is not None:\n",
    "            for unit in wilcoxon_df.columns.tolist():\n",
    "                if wilcoxon_df[unit][1] < p_value:\n",
    "                      units_to_plot.append(unit)\n",
    "        else:\n",
    "            if units is None:\n",
    "                units_to_plot = wilcoxon_df.columns.tolist()\n",
    "            else:\n",
    "                units_to_plot = units\n",
    "        no_plots = len(units_to_plot)\n",
    "        height_fig = math.ceil(no_plots/3)\n",
    "        i = 1\n",
    "        plt.figure(figsize=(20,4*height_fig))\n",
    "        unit_event_firing_rates = self.get_unit_event_firing_rates(\n",
    "            recording,\n",
    "            event,\n",
    "            equalize,\n",
    "            baseline,\n",
    "            0\n",
    "            )\n",
    "        x_stop = recording.wilcox_xstop\n",
    "        for unit in units_to_plot:\n",
    "            mean_arr = np.mean(unit_event_firing_rates[unit], axis=0)\n",
    "            sem_arr = sem(unit_event_firing_rates[unit], axis=0)\n",
    "            p_value = wilcoxon_df[unit][1]\n",
    "            x = np.linspace(start=-baseline,stop=x_stop,num=len(mean_arr))\n",
    "            plt.subplot(height_fig,3,i)\n",
    "            plt.plot(x, mean_arr, c= 'b')\n",
    "            plt.axvline(x=0, color='r', linestyle='--')\n",
    "            plt.fill_between(x, mean_arr-sem_arr, mean_arr+sem_arr, alpha=0.2)\n",
    "            plt.title(f'Unit {unit} Average (p={p_value})')\n",
    "            i+=1\n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "\n",
    "    def wilcoxon_event_v_event_stats(self, recording, event1, event2, equalize):\n",
    "        #another function that uses the equalize parameter \n",
    "        \"\"\"\n",
    "        calculates wilcoxon signed-rank test for average firing rates between\n",
    "        two events for a given recording. the resulting dataframe of wilcoxon stats\n",
    "        and p values for every unit is added to a dictionary of dataframes for that\n",
    "        recording. \n",
    "\n",
    "        Key for this dictionary item is '{event1} vs {event2}' \n",
    "        and the value is the dataframe. \n",
    "        \n",
    "        Args (4 total):\n",
    "            recording: EphysRecording instance\n",
    "            event1: str, first event type firing rates for stats to be run on\n",
    "            event2: str, second event type firing rates for stats to be run on\n",
    "            equalize: {user_defined(float), 'max', 'average'}, equalizes lengths of events\n",
    "                by padding with post event time or trimming event\n",
    "                user_defined: float, makes all events user_defined (s) long   \n",
    "                'max': makes all events as long as the longest event \n",
    "                'average': makes all events as long as the average event length\n",
    "    \n",
    "        Return (1):\n",
    "            wilcoxon_df: pandas dataframe, columns are unit ids, \n",
    "            row[0] are wilcoxon statistics and row[1] are p values \n",
    "        \n",
    "        \"\"\"\n",
    "        unit_event1_firing_rates = self.get_unit_event_firing_rates(recording, event1, equalize, 0, 0)\n",
    "        unit_event2_firing_rates = self.get_unit_event_firing_rates(recording, event2, equalize, 0, 0)\n",
    "        unit_averages = {}\n",
    "        for unit in unit_event1_firing_rates.keys():\n",
    "            try:\n",
    "                event1_averages = [mean(event) for event in unit_event1_firing_rates[unit]]\n",
    "                event2_averages = [mean(event) for event in unit_event2_firing_rates[unit]]\n",
    "                unit_averages[unit] = [event1_averages, event2_averages]\n",
    "            except:\n",
    "                print(f'Unit {unit} has {len(recording.unit_timestamps[unit])} spikes')\n",
    "        wilcoxon_stats = {}\n",
    "        for unit in unit_averages.keys(): \n",
    "            wilcoxon_stats[unit] = wilcoxon(unit_averages[unit][0], unit_averages[unit][1], method = 'approx')\n",
    "        wilcoxon_df = pd.DataFrame.from_dict(wilcoxon_stats)\n",
    "        wilcox_key = f'{event1 } vs {event2}'\n",
    "        recording.wilcox_dfs[wilcox_key] = wilcoxon_df\n",
    "        return wilcoxon_df\n",
    "\n",
    "    def wilcox_event_v_event_collection(self, event1, event2, equalize):  \n",
    "        \"\"\" \n",
    "        Runs a wilcoxon signed rank test on all good units of \n",
    "        all recordings in the collection on the \n",
    "        given event's firing rate versus another given event's firing rate.\n",
    "    \n",
    "        Creates a dataframe with rows for each unit and columns representing \n",
    "        Wilcoxon stats, p values, orginal unit ids, recording,\n",
    "        subject and the events given.  Dataframe is saved in the collections\n",
    "        wilcox_dfs dictionary, key is '{event1} vs {event2}' \n",
    "\n",
    "        Args(3 total):\n",
    "            event: str, event firing rates for stats to be run on \n",
    "            baseline_window: float, time (s) prior to event for stats to be run on\n",
    "            equalize: {user_defined(float), 'max', 'average'}, equalizes lengths of events\n",
    "                by padding with post event time or trimming event\n",
    "                user_defined: float, makes all events user_defined (s) long   \n",
    "                'max': makes all events as long as the longest event \n",
    "                'average': makes all events as long as the average event length\n",
    "        \"\"\"\n",
    "        is_first = True\n",
    "        for recording_name, recording in self.collection.item():\n",
    "            recording_df = self.wilcox_event_v_event_stats(self, recording, event1, event2, equalize)\n",
    "            recording_df = recording_df.transpose().reset_index()\n",
    "            recording_df = recording_df.rename(column={'index':'original unit id'})\n",
    "            recording_df['Recording'] = recording_name\n",
    "            recording_df['Subject'] = recording.subject\n",
    "            recording_df['Event'] = [event1, event2]\n",
    "            master_df = pd.concat([master_df, recording_df], axis=0).reset_index(drop=True)\n",
    "            if is_first:\n",
    "                master_df = recording_df\n",
    "                is_first = False\n",
    "            else:\n",
    "                master_df = pd.concat([master_df, recording_df], axis=0).reset_index(drop=True)\n",
    "        wilcox_key = f'{event1} vs {event2}'\n",
    "        self.wilcox_dfs[wilcox_key] = master_df\n",
    "        return master_df\n",
    "\n",
    "    def get_zscore(self, recording, event, baseline_window, equalize):\n",
    "        #have to deal with the equalize parameter \n",
    "        events = recording.event_dict[event]\n",
    "        preevent_baselines = np.array([pre_event_window(event, baseline_window) for event in events])\n",
    "        unit_event_firing_rates = self.get_unit_event_firing_rates(recording, baseline_window, 0, equalize)\n",
    "        unit_preevent_firing_rates = self.get_unit_event_firing_rates(recording, 0,0,False,preevent_baselines)\n",
    "        zscored_events = {}\n",
    "        for unit in unit_event_firing_rates:\n",
    "            #calculate average event across all events per unit\n",
    "            event_average = np.mean(unit_event_firing_rates[unit], axis = 0)\n",
    "            #one average for all preevents \n",
    "            preevent_average = np.mean(unit_preevent_firing_rates[unit], axis = 0)\n",
    "            mew = np.mean(preevent_average)\n",
    "            sigma = np.std(preevent_average)\n",
    "            zscored_event = [(event_bin - mew)/sigma for event_bin in event_average]\n",
    "            zscored_events[unit] = zscored_event\n",
    "        recording.zscored_events[event] = zscored_events\n",
    "        if equalize == 'average':\n",
    "            zscore_xstop = recording.mean_event_length\n",
    "        if equalize == 'max':\n",
    "            zscore_xstop = recording.longest_event\n",
    "        else:\n",
    "            zscore_xstop = equalize*1000\n",
    "        return zscored_events\n",
    "        \n",
    "    def get_zscore_collection(self, event, baseline_window, equalize):\n",
    "        is_first = True \n",
    "        for recording_name, recording in self.collection.values():\n",
    "            zscored_events = self.get_zscore(recording, event, baseline_window, equalize)\n",
    "            zscored_events_df = pd.DataFrame.from_dict(zscored_events, orient='index')\n",
    "            zscored_events_df = zscored_events_df.reset_index().rename(column={'index': 'original unit id'})\n",
    "            zscored_events_df['Recording'] = recording_name\n",
    "            zscored_events_df['Subject'] = recording.subject\n",
    "            zscored_events_df['Event'] = [event, baseline_window]\n",
    "            if is_first:\n",
    "                master_df = zscored_events_df\n",
    "                is_first = False    \n",
    "            else:\n",
    "                master_df = pd.concat([master_df, zscored_events_df], axis=0).reset_index(drop=True)\n",
    "        zscore_key = f'{event} vs {baseline_window}second baseline'\n",
    "        self.collection.zscored_events[zscore_key] = master_df\n",
    "        \n",
    "    def get_zcore_plot(self, recording, event, zscore_xstop, baseline_window, max_event, title):\n",
    "        plt.figure(figsize=(20,6))\n",
    "        zscored_unit_event_firing_rates = recording.zscored_events[event]\n",
    "        zscore_pop = np.array(list(zscored_unit_event_firing_rates.values()))\n",
    "        mean_arr = np.mean(zscore_pop, axis=0)\n",
    "        sem_arr = sem(zscore_pop, axis=0)\n",
    "        x = np.linspace(start=-baseline_window,stop=zscore_xstop,num=len(mean_arr))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(x, mean_arr, c= 'b')\n",
    "        plt.axvline(x=0, color='r', linestyle='--')\n",
    "        plt.fill_between(x, mean_arr-sem_arr, mean_arr+sem_arr, alpha=0.2)\n",
    "        plt.title(f'Population z-score {event}')\n",
    "        plt.subplot(1,2,2)\n",
    "        for unit in zscored_unit_event_firing_rates.keys():\n",
    "            plt.plot(x, zscored_unit_event_firing_rates[unit], linewidth = .5)\n",
    "            plt.axvline(x=0, color='r', linestyle='--')\n",
    "            plt.title(f'Unit z-score {event} event')\n",
    "        plt.suptitle(f'{title} Z-scored average {event} event')\n",
    "        plt.show()        \n",
    "\n",
    "    def PCA_trajectories(self, events, equalize, n_components=2, pre_window = 0, post_window = 0):\n",
    "        first_event = True\n",
    "        first_recording = True\n",
    "        for recording_name, recording in self.collection.items():\n",
    "            no_units = len(list(recording.unit_firing_rates.keys()))\n",
    "            unit_key = [recording_name] * len(no_units)\n",
    "            for event in events:\n",
    "                unit_event_firing_rates = self.get_unit_event_firing_rates(recording, event, equalize, pre_window, post_window)\n",
    "                \n",
    "                unit_event_average = get_unit_average_events(unit_event_firing_rates) \n",
    "                if first_event:\n",
    "                    PCA_matrix = [value for sublist in unit_event_average.values() for value in sublist]\n",
    "                    PCA_key = [event] * len(PCA_matrix)\n",
    "                    first_event = False\n",
    "                else:\n",
    "                    next_event = [value for sublist in unit_event_average.values() for value in sublist]\n",
    "                    PCA_matrix = np.concatenate([PCA_matrix, next_event], axis=0)\n",
    "                    next_event_key = [event] * len(next_event)\n",
    "                    PCA_key = PCA_key + next_event_key\n",
    "            if first_recording:\n",
    "                master_key = unit_key\n",
    "                first_recording = False\n",
    "            else:\n",
    "                master_key = master_key + unit_key\n",
    "        pca = PCA(n_components)\n",
    "        transformed_matrix = pca.fit_transform(PCA_matrix)\n",
    "        PCA_df = pd.DataFrame({'data': transformed_matrix, 'index': master_key, 'columns': PCA_key})\n",
    "        self.collection.PCA_df = PCA_df \n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot = EphysRecordingCollection(\"C://Users//megha//Documents//GitHub//diff_fam_social_memory_ephys//proc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2\n",
       "0  6  1\n",
       "1  0  2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "recording_name = 'recording'\n",
    "recording2_name = 'recording2'\n",
    "recording = {'1': [1.3, 2.3], '2': [3.4, 5]}\n",
    "recording2 = {'1': [6, 0], '2': [1, 2]}\n",
    "recording_df = pd.DataFrame(recording)\n",
    "recording2_df = pd.DataFrame(recording2)\n",
    "recording2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Recording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>recording</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>recording</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index    0    1  Recording\n",
       "0     1  1.3  2.3  recording\n",
       "1     2  3.4  5.0  recording"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording2_df = recording2_df.transpose().reset_index()\n",
    "recording_df = recording_df.transpose().reset_index()\n",
    "recording_df['Recording'] = recording_name\n",
    "recording2_df['Recording'] = recording2_name\n",
    "recording_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original unit id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Recording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>recording2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>recording2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original unit id  0  1   Recording\n",
       "0                1  6  0  recording2\n",
       "1                2  1  2  recording2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording2_df = recording2_df.rename(columns={'index': 'original unit id'})\n",
    "recording_df = recording_df.rename(columns={'index': 'original unit id'})\n",
    "recording2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.concat([recording_df, recording2_df], axis = 0).reset_index(drop=True)\n",
    "master_df\n",
    "\n",
    "wilcox_dict = {recording_name: recording_df, recording2_name: recording2_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'recording vs recording2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_name + ' vs ' + recording2_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "play",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
