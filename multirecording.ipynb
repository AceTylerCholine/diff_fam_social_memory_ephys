{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve\n",
    "from scipy.signal import savgol_filter\n",
    "import math\n",
    "import boris_extraction as boris\n",
    "import pandas as pd\n",
    "from scipy.stats import sem\n",
    "from scipy.stats import ranksums\n",
    "from statistics import mean\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.decomposition import PCA\n",
    "from statistics import StatisticsError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_spiketrain(timestamp_array, timebin =1, sampling_rate=20000):\n",
    "    \"\"\"\n",
    "    creates a spiketrain of ms time bins \n",
    "    each array element is the number of spikes recorded per ms\n",
    "    \n",
    "    Args (3 total):\n",
    "        timestamp_array: numpy array, spike timestamp array\n",
    "        timebin: int, default=1, timebin (ms) of resulting spiketrain\n",
    "        sampling_rate: int, default=20000, sampling rate in Hz of the ephys recording\n",
    "        \n",
    "    Returns (1):\n",
    "        spiketrain: numpy array, array elements are number of spikes per timebin\n",
    "    \"\"\"\n",
    "    \n",
    "    hz_to_timebin = int(sampling_rate*.001*timebin)\n",
    "    spiketrain = np.histogram(timestamp_array, bins=np.arange(0, timestamp_array[-1], hz_to_timebin))[0]\n",
    "    \n",
    "    return spiketrain\n",
    "\n",
    "def get_firing_rate(spiketrain, smoothing_window = 250, timebin=1):\n",
    "    \"\"\"\n",
    "    calculates firing rate (spikes/second)\n",
    "    \n",
    "    Args (3 total, 1 required):\n",
    "        spiketrain: numpy array, in timebin (ms) bins\n",
    "        smoothing_window: int, default=250, smoothing average window (ms)\n",
    "            min smoothing_window = 1\n",
    "        timebin: int, default = 1, timebin (ms) of spiketrain\n",
    "\n",
    "    Return (1):\n",
    "        firing_rate: numpy array of firing rates in timebin sized windows\n",
    "        \n",
    "    \"\"\" \n",
    "    weights = np.ones(smoothing_window) / smoothing_window * 1000 / timebin \n",
    "    firing_rate = np.convolve(spiketrain, weights, mode='same')\n",
    "\n",
    "    return firing_rate\n",
    "\n",
    "\n",
    "def get_event_lengths(events):\n",
    "    \"\"\"\n",
    "    calculates event lengths and longest event length\n",
    "\n",
    "    Args (1):\n",
    "        events:numpy array of [[start (ms), stop (ms)] x n events]\n",
    "\n",
    "    Returns (2):\n",
    "        max event length: int, longest event length in ms\n",
    "        event_lengths: lst of ints, event lengths in ms\n",
    "    \"\"\"\n",
    "    event_lengths = []\n",
    "    for i in range(len(events[0])+1):\n",
    "        event_length = int(events[i][1] - events[i][0])\n",
    "        event_lengths.append(event_length)\n",
    "    return max(event_lengths), event_lengths, mean(event_lengths)\n",
    "\n",
    "\n",
    "def trim_event(event, max_event):\n",
    "    \"\"\"\n",
    "    trims events to a given length\n",
    "    Args (2 total):\n",
    "        events:numpy array of [[start (ms), stop (ms)] x n events]\n",
    "        max_event: int, max length (s) of event desired\n",
    "\n",
    "    Returns (1):\n",
    "        events:numpy array of [[start (ms), stop (ms)] x n events]\n",
    "        with none longer than max_event\n",
    "    \"\"\"\n",
    "    if event[1] - event[0] > (max_event*1000):\n",
    "        event[1] = event[0]+(max_event*1000)\n",
    "        event[0] = event[0]  \n",
    "    return np.array(event)\n",
    "\n",
    "\n",
    "def pre_event_window(event, baseline_window):\n",
    "    \"\"\"\n",
    "    creates an event like object np.array[start(ms), stop(ms)] for\n",
    "    baseline_window amount of time prior to an event\n",
    "\n",
    "    Args (2 total):\n",
    "        event: np.array[start(ms), stop(ms)]\n",
    "        baseline_window: int, seconds prior to an event\n",
    "\n",
    "    Returns (1):\n",
    "        preevent: np.array, [start(ms),stop(ms)] baseline_window (s) before event\n",
    "    \"\"\"\n",
    "    preevent = [event[0] - (baseline_window*1000)-1, event[0]-1]\n",
    "    return np.array(preevent)\n",
    "\n",
    "\n",
    "def max_events(unit_dict, max_event, pre_window, timebin = 1):\n",
    "    \"\"\"\n",
    "    creates a dictionary with unit firing rates during events no longer\n",
    "    than max_event (s) (all longer events will be trimmed) and start times\n",
    "    adjusted to include pre_window time (s)\n",
    "\n",
    "    Args (4 total):\n",
    "        unit_dict: dict, unit id as keys, and values are spiketrains or firing rates \n",
    "        max_event: int, longest event length (s) returned (all longer events will be trimmed)\n",
    "        pre_window: int, amount of preevent time (s) returned\n",
    "        timebin: timebin (ms) of dict\n",
    "\n",
    "    Returns (1):\n",
    "        snippets_dict: dict, unit id as keys, values are spiketrains or firing rates during\n",
    "        pre_window and up until max event \n",
    "    \"\"\"\n",
    "    \n",
    "    snippets_dict = {}\n",
    "    for unit in unit_dict.keys():\n",
    "        events = unit_dict[unit]\n",
    "        try:\n",
    "            events = [event[0:int((pre_window + max_event)*1000/timebin)] for event in events]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        snippets_dict[unit] = events\n",
    "    return snippets_dict\n",
    "\n",
    "\n",
    "def get_unit_average_events(unit_event_snippets):\n",
    "    unit_average_event = {}\n",
    "    for unit in unit_event_snippets.keys():\n",
    "        unit_average_event[unit] = np.mean(unit_event_snippets[unit], axis=0)\n",
    "    return unit_average_event\n",
    "\n",
    "\n",
    "class EphysRecording:\n",
    "    \"\"\"\n",
    "    A class for an ephys recording after being spike sorted and manually curated using phy. \n",
    "    Ephys recording must have a phy folder. \n",
    "\n",
    "    Attributes:\n",
    "        path: str, relative path to the phy folder\n",
    "            formatted as: './folder/folder/phy'\n",
    "        subject: str, subject id who was being recorded\n",
    "        sampling_rate: int, sampling rate of the ephys device\n",
    "            in Hz, standard in the PC lab is 20,000Hz\n",
    "        timestamps_var: numpy array, all spike timestamps \n",
    "            of good and mua units (no noise unit-generated spikes)\n",
    "        unit_array: numpy array, unit ids associated with each\n",
    "            spike in the timestamps_var\n",
    "        labels_dict: dict, keys are unit ids (str) and\n",
    "            values are labels (str)\n",
    "        unit_timestamps: dict, keys are unit ids (int), and\n",
    "            values are numpy arrays of timestamps for all spikes \n",
    "            from \"good\" units only \n",
    "        spiketrain: np.array, spiketrain of number of spikes in a specified timebin\n",
    "        unit_spiketrains: dict, spiketrains for each unit\n",
    "            keys: str, unit ids\n",
    "            values: np.array, number of spikes per specified timebin\n",
    "        unit_firing_rates: dict, firing rates per unit\n",
    "            keys: str, unit ids\n",
    "            values: np.arrays, firing rate of unit in a specified timebin \n",
    "                    calculated with a specified smoothing window\n",
    "\n",
    "    Methods: (all called in __init__)\n",
    "        get_unit_labels: creates labels_dict\n",
    "        get_spike_specs: creates timestamps_var and unit_array\n",
    "        get_unit_timestamps: creates unit_timestamps dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path, sampling_rate=20000):\n",
    "        \"\"\"\n",
    "        constructs all necessary attributes for the EphysRecording object\n",
    "        including creating labels_dict, timestamps_var, and a unit_timstamps \n",
    "        dictionary \n",
    "        \n",
    "        Arguments (2 total):\n",
    "            path: str, relative path to the phy folder\n",
    "                formatted as: './folder/folder/phy'\n",
    "            sampling_rate: int, default=20000; sampling rate of \n",
    "                the ephys device in Hz\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.zscored_events = {}\n",
    "        self.wilcox_dfs = {}\n",
    "        self.get_unit_labels()\n",
    "        self.get_spike_specs()\n",
    "        self.get_unit_timestamps()\n",
    "\n",
    "    \n",
    "    def get_unit_labels(self):\n",
    "        \"\"\"\n",
    "        assigns self.labels_dicts as a dictionary \n",
    "        with unit id (str) as key and label as values (str)\n",
    "        labels: 'good', 'mua', 'noise' \n",
    "\n",
    "        Arguments:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        labels = 'cluster_group.tsv'\n",
    "        with open(os.path.join(self.path, labels), 'r') as f:\n",
    "            reader = csv.DictReader(f, delimiter='\\t')\n",
    "            self.labels_dict = {row['cluster_id']: row['group'] for row in reader}\n",
    "\n",
    "    \n",
    "    def get_spike_specs(self):\n",
    "        \"\"\"\n",
    "        imports spike_time and spike_unit from phy folder\n",
    "        deletes spikes from units labeled noise in unit and timestamp array\n",
    "        and assigns self.timstamps_var (numpy array) as the remaining timestamps \n",
    "        and assigns self.unit_array (numpy array) as the unit ids associated\n",
    "        with each spike\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            None \n",
    "        \"\"\"\n",
    "        timestamps = 'spike_times.npy'\n",
    "        unit = 'spike_clusters.npy'\n",
    "        timestamps_var = np.load(os.path.join(self.path, timestamps))\n",
    "        unit_array = np.load(os.path.join(self.path, unit))\n",
    "        spikes_to_delete = []\n",
    "        for spike in range(len(timestamps_var)): \n",
    "            if self.labels_dict[unit_array[spike].astype(str)] == 'noise':\n",
    "                spikes_to_delete.append(spike)\n",
    "        self.timestamps_var = np.delete(timestamps_var, spikes_to_delete)\n",
    "        self.unit_array = np.delete(unit_array, spikes_to_delete)\n",
    "\n",
    "    \n",
    "    def get_unit_timestamps(self):\n",
    "        \"\"\"\n",
    "        creates a dictionary of units to spike timestamps\n",
    "        keys are unit ids (int) and values are spike timestamps for that unit (numpy arrays)\n",
    "        and assigns dictionary to self.unit_timestamps\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "        \n",
    "        Return:\n",
    "            None\n",
    "        \"\"\"\n",
    "        \n",
    "        unit_timestamps = {}\n",
    "        for spike in range(len(self.timestamps_var)): \n",
    "            if self.unit_array[spike] in unit_timestamps.keys():\n",
    "                timestamp_list = unit_timestamps[self.unit_array[spike]] \n",
    "                timestamp_list = np.append(timestamp_list, self.timestamps_var[spike])\n",
    "                unit_timestamps[self.unit_array[spike]] = timestamp_list\n",
    "            else:\n",
    "                unit_timestamps[self.unit_array[spike]] = self.timestamps_var[spike]\n",
    "        \n",
    "        self.unit_timestamps = unit_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EphysRecordingCollection:\n",
    "    #this should have an event dictionary baked into it as well as subject per recording\n",
    "    #and an initiated\n",
    "    def __init__(self, path, sampling_rate=20000):\n",
    "\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.path = path \n",
    "        self.wilcox_dfs = {}\n",
    "        self.zscored_events = {}\n",
    "        self.make_collection()\n",
    "\n",
    "    def make_collection(self):\n",
    "        \n",
    "        collection = {}\n",
    "        for root, dirs, files in os.walk(self.path):\n",
    "            for directory in dirs:\n",
    "                if directory.endswith('merged.rec'):\n",
    "                    tempobject = EphysRecording(os.path.join(self.path, directory, 'phy'), self.sampling_rate)\n",
    "                    collection[directory] = tempobject\n",
    "        self.collection = collection\n",
    "\n",
    "\n",
    "    def get_by_name(self, name):\n",
    "        return self.collection[name] \n",
    "\n",
    "    # def assign_events(self):\n",
    "    #     for root, dirs, files in os.walk(self.path):\n",
    "    #         for directory in dirs:\n",
    "    #             if directory.endswith('merged.rec'):\n",
    "    #                 reader = csv.DictReader(f, delimter='\\t')\n",
    "    #                 self.collection[directory].event_dict = {row['event']: row['start&stop'] for row in reader}\n",
    "\n",
    "    \n",
    "class SpikeAnalysis_MultiRecording:\n",
    "    \"\"\"\n",
    "    A class for ephys statistics done on multiple event types for multiple recordings\n",
    "\n",
    "    where keys are event type names and values are arrays [[start (ms), stop(ms)]..]\n",
    "    \n",
    "\n",
    "    Attributes:\n",
    "        event_dict: dict, dictionary of event names and event start and stop times\n",
    "            key: str, name of the event \n",
    "            value: numpy array of [[start (ms), stop (ms)] x n events]\n",
    "        event_types: lst of strs, from the keys of the event dict\n",
    "        events: list of all start and stop times from event types \n",
    "        smoothing_window: int, default=250, window length in ms used to calculate firing rates\n",
    "        timebin: int, default=1, bin size (in ms) for spike train and firing rate arrays\n",
    "        ignore_freq: int, default=0, frequency in Hz that a good unit needs to fire at to be included in analysis\n",
    "        longest_event: int, length of longest event (ms)\n",
    "        event_lengths: lst, length of all events (ms)\n",
    "\n",
    "    Methods: \n",
    "        get_whole_spiketrain: \n",
    "        get_unit_spiketrains: \n",
    "        get_unit_firing_rates: \n",
    "        get_event_snippets:\n",
    "        get_unit_event_firing_rates:\n",
    "        wilcox_baseline_v_event_stats:\n",
    "        wilcox_baseline_v_event_plots:\n",
    "    \"\"\"\n",
    "    def __init__(self, collection, smoothing_window=250, timebin=1, ignore_freq=0.01):\n",
    "        #each recording within the collection should have its own event dictionary as an attribute\n",
    "        \n",
    "        self.collection = collection\n",
    "        self.smoothing_window = smoothing_window\n",
    "        self.timebin = timebin\n",
    "        self.ignore_freq = ignore_freq\n",
    "        self.get_event_types()\n",
    "        self.get_whole_spiketrain()\n",
    "        self.get_unit_spiketrains()\n",
    "        self.get_unit_firing_rates()\n",
    "\n",
    "    ## add function that gets list of events from all recording event_dicts ##\n",
    "    ## and throws errors when any recording has a different dict ##\n",
    "\n",
    "    def get_event_types(self):\n",
    "        ...\n",
    "\n",
    "    def get_whole_spiketrain(self):\n",
    "        \"\"\"\n",
    "        creates a spiketrain with timebin length timebins \n",
    "        for each recording in the collection\n",
    "        each array element is the number of spikes per timebin\n",
    "\n",
    "        each spiketrian is assigned as an attribute for that recording\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "         \n",
    "        \"\"\"\n",
    "        for recording in self.collection.values():\n",
    "            recording.spiketrain = get_spiketrain(recording.timestamps_var, recording.sampling_rate, self.timebin)\n",
    "    \n",
    "    def get_unit_spiketrains(self):  \n",
    "        \"\"\"\n",
    "        Creates a dictionary and assigns it as recording.unit_spiketrains\n",
    "        for each recording in the collection\n",
    "        where keys are 'good' unit ids (int) (not 'mua') that reach\n",
    "        a threshold frequency, values are numpy arrays of \n",
    "        spiketrains in timebin sized bins\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "            \n",
    "        Reutrns:\n",
    "            None\n",
    "            \n",
    "        \"\"\"\n",
    "        sampling_rate = self.collection.sampling_rate\n",
    "        for recording in self.collection.values():\n",
    "                unit_spiketrains = {}\n",
    "                freq_dict = {}\n",
    "                for unit in recording.unit_timestamps.keys():\n",
    "                    if recording.labels_dict[str(unit)] == 'good':\n",
    "                        no_spikes = len(recording.unit_timestamps[unit])\n",
    "                        unit_freq = no_spikes/recording.timestamps_var[-1]*sampling_rate\n",
    "                        freq_dict[unit] = unit_freq\n",
    "                        if unit_freq > self.ignore_freq:\n",
    "                            unit_spiketrains[unit] = get_spiketrain(recording.unit_timestamps[unit], \n",
    "                                                                    sampling_rate, \n",
    "                                                                    self.timebin)\n",
    "                recording.unit_spiketrains = unit_spiketrains    \n",
    "                recording.freq_dict = freq_dict\n",
    "    \n",
    "    def get_unit_firing_rates(self):  \n",
    "        \"\"\"\n",
    "        Calculates firing rates per unit per recording in collection,\n",
    "        creates a dictionary and assigns it as recording.unit_firing_rates\n",
    "        the keys are unit ids (int) and values are firing rates for the\n",
    "        unit (numpy array) in timebin sized bins \n",
    "        calculated using smoothing_window for averaging\n",
    "        \n",
    "        Args:\n",
    "            none\n",
    "            \n",
    "        Returns:\n",
    "            none\n",
    "        \"\"\"\n",
    "        for recording in self.collection.values():\n",
    "            unit_firing_rates = {}\n",
    "            for unit in recording.unit_spiketrains.keys():\n",
    "                unit_firing_rates[unit] = get_firing_rate(recording.unit_spiketrains[unit],\n",
    "                                                        self.smoothing_window, \n",
    "                                                        self.timebin)\n",
    "            recording.unit_firing_rates = unit_firing_rates\n",
    "    \n",
    "    def get_event_snippets(self, recording, event, whole_recording, equalize, pre_window=0, post_window=0):\n",
    "        \"\"\"\n",
    "        takes snippets of spiketrains or firing rates for events\n",
    "        optional pre-event and post-event windows (s) may be included\n",
    "        all events can also be of equal length by extending \n",
    "        snippet lengths to the longest event\n",
    "    \n",
    "        Args (6 total, 4 required): \n",
    "            recording: EphysRecording instance, which recording the snippets come from\n",
    "            event: str, event type of which ehpys snippets happen during\n",
    "            whole_recording: numpy array, spiketrain or firing rates \n",
    "                for the whole recording, for population or for a single unit\n",
    "            pre_window: int, default=0, seconds prior to start of event returned\n",
    "            post_window: int, default=0, seconds after end of event returned\n",
    "            equalize: float, length (s) of events used by padding with post event time\n",
    "                or trimming events all to equalize (s) long \n",
    "      \n",
    "    \n",
    "        Returns (1):\n",
    "            event_snippets: a list of lists, where each list is a list of firing rates\n",
    "                or spiketrains during an event including pre_window&post_windows, \n",
    "                accounting for equalize and timebins\n",
    "        \"\"\" \n",
    "        if type(event) == str:    \n",
    "            events = recording.event_dict[event]\n",
    "        else:\n",
    "            events = event\n",
    "        event_snippets = []\n",
    "        pre_window = math.ceil(pre_window*1000)\n",
    "        post_window = math.ceil(post_window*1000)\n",
    "        equalize = equalize*1000\n",
    "        for i in range(events.shape[0]):\n",
    "            pre_event = math.ceil((events[i][0] - pre_window)/self.timebin)\n",
    "            post_event = math.ceil((events[i][0] + post_window + equalize)/self.timebin)\n",
    "            event_snippet = whole_recording[pre_event:post_event]\n",
    "            if len(event_snippet) == (equalize + post_window + pre_window)/self.timebin:\n",
    "                #cutting events at end of recording\n",
    "                event_snippets.append(event_snippet)\n",
    "        return event_snippets\n",
    "    \n",
    "    def get_unit_event_firing_rates(self, recording, event, equalize, pre_window = 0, post_window = 0):\n",
    "        \"\"\"\n",
    "        returns firing rates for events per unit\n",
    "    \n",
    "        Args (5 total, 3 required): \n",
    "            recording: EphysRecording instance, which recording the snippets come from\n",
    "            event: str, event type of which ehpys snippets happen during\n",
    "            equalize: float, length (s) of events used by padding with post event time\n",
    "                or trimming events all to equalize (s) long\n",
    "            pre_window: int, default=0, seconds prior to start of event returned\n",
    "            post_window: int, default=0, seconds after end of event returned\n",
    "            \n",
    "        Return (1):\n",
    "            unit_event_firing_rates: dict, keys are unit ids (???),\n",
    "            values are lsts of numpy arrays of firing rates per event\n",
    "        \"\"\"\n",
    "        unit_event_firing_rates = {}\n",
    "        for unit in recording.unit_firing_rates.keys():\n",
    "            unit_event_firing_rates[unit] = self.get_event_snippets(recording, recording.event, recording.unit_firing_rates[unit], equalize, pre_window, post_window)\n",
    "        return unit_event_firing_rates\n",
    "    \n",
    "    def wilcox_baseline_v_event_stats(self, recording, event, equalize, baseline_window):\n",
    "        \"\"\"\n",
    "        calculates wilcoxon signed-rank test for average firing rates of two windows: event vs baseline\n",
    "        baseline used is an amount of time immediately prior to the event\n",
    "        wilcoxon signed-rank test is applied to two sets of measurements:\n",
    "        average firing rate per event, average firing rate per baseline.\n",
    "        the resulting dataframe of wilcoxon stats and p values for every unit \n",
    "        is added to a dictionary of dataframes for that recording. \n",
    "\n",
    "        Key for this dictionary item is '{event} vs {baselinewindow}second baseline' \n",
    "        and the value is the dataframe. \n",
    "        \n",
    "        Args (4 total, 4 required):\n",
    "            recording: EphysRecording instance, which recording the snippets come from\n",
    "            event: str, event type of which ehpys snippets happen during\n",
    "            equalize: float, length (s) of events used by padding with post event time\n",
    "                or trimming events all to equalize (s) long used in stat\n",
    "            baseline_window: int, default=0, seconds prior to start of event used in stat\n",
    "    \n",
    "        Return (1):\n",
    "            wilcoxon_df: pandas dataframe, columns are unit ids, \n",
    "            row[0] are wilcoxon statistics and row[1] are p values \n",
    "        \n",
    "        \"\"\"\n",
    "        #this is another one where i gotta figure out/edit the equalize fxn\n",
    "        preevent_baselines = np.array([pre_event_window(event, baseline_window) for event in recording.event_dict[event]])\n",
    "        unit_preevent_firing_rates = self.get_unit_event_firing_rates(recording, preevent_baselines, baseline_window, 0, 0)\n",
    "        unit_event_firing_rates = self.get_unit_event_firing_rates(recording, event, equalize, 0, 0)\n",
    "        unit_averages = {}\n",
    "        for unit in unit_event_firing_rates.keys():\n",
    "            try:\n",
    "                event_averages = [mean(event) for event in unit_event_firing_rates[unit]]\n",
    "                preevent_averages = [mean(event) for event in unit_preevent_firing_rates[unit]]\n",
    "                # cut preevent to events that have been cut\n",
    "                min_length = min(len(event_averages), len(preevent_averages))\n",
    "                preevent_averages = preevent_averages[:min_length]\n",
    "                event_averages = event_averages[:min_length]\n",
    "                unit_averages[unit] = [event_averages, preevent_averages]\n",
    "            except StatisticsError as e:\n",
    "                print(f'Unit {unit} has {len(recording.unit_timestamps[unit])} spikes')\n",
    "        wilcoxon_stats = {}\n",
    "        for unit in unit_averages.keys(): \n",
    "            wilcoxon_stats[unit] = wilcoxon(unit_averages[unit][0], unit_averages[unit][1], method = 'approx')\n",
    "        wilcoxon_df = pd.DataFrame.from_dict(wilcoxon_stats)\n",
    "        wilcoxon_df.index = ['Wilcoxon Stat', 'p value']\n",
    "        wilcox_key = f'{event} vs {baseline_window}second baseline'\n",
    "        recording.wilcox_dfs[wilcox_key] = wilcoxon_df\n",
    "        return wilcoxon_df\n",
    "\n",
    "    # def fishers_exact_wilcox(self, baseline_window, equalize):\n",
    "    #     sig_units = {}\n",
    "    #     for event in self.event_dict.keys():\n",
    "    #         wilcox_df = self.wilcox_baseline_v_event_stats(event, baseline_window, equalize) \n",
    "    #         sig_units[event] = (len(wilcox_df[(wilcox_df[1]<=0.05)]), len(wilcox_df[(wilcox_df[1]>.05)])) \n",
    "    #     fishers_df = pd.DataFrame(sig_units.values(), index=sig_units.keys(), columns=['Significant', 'Not Significant'])\n",
    "\n",
    "    def wilcox_baseline_v_event_collection(self, event, baseline_window, equalize):  \n",
    "        \"\"\"\n",
    "        Runs a wilcoxon signed rank test on all good units of \n",
    "        all recordings in the collection on the \n",
    "        given event's firing rate versus the given baseline window.\n",
    "        Baseline window is the amount of time immediately prior to the event\n",
    "        whose firing rate is being compared. \n",
    "\n",
    "        Creates a dataframe with rows for each unit and columns representing \n",
    "        Wilcoxon stats, p values, orginal unit ids, recording,\n",
    "        subject and the event + baselien given. Dataframe is saved in the collections\n",
    "        wilcox_dfs dictionary, key is '{event} vs {baseline_window}second baseline'\n",
    "\n",
    "        Args(3 total):\n",
    "            event: str, event firing rates for stats to be run on \n",
    "            equalize: float, length (s) of events used by padding with post event time\n",
    "                or trimming events all to equalize (s) long used in stat\n",
    "            baseline_window: int, default=0, seconds prior to start of event used in stat\n",
    "        Returns(1):\n",
    "            master_df: df, rows for each unit and columns representing \n",
    "                       Wilcoxon stats, p values, orginal unit ids, recording\n",
    "        \"\"\"\n",
    "        is_first = True\n",
    "        for recording_name, recording in self.collection.item():\n",
    "            recording_df = self.wilcox_baseline_v_event_stats(self, recording, event, equalize, baseline_window)\n",
    "            recording_df = recording_df.transpose().reset_index()\n",
    "            recording_df = recording_df.rename(column={'index': 'original unit id'})\n",
    "            recording_df['Recording'] = recording_name\n",
    "            recording_df['Subject'] = recording.subject\n",
    "            recording_df['Event'] = [event, baseline_window] \n",
    "            if is_first:\n",
    "                master_df = recording_df\n",
    "                is_first = False\n",
    "            else:\n",
    "                master_df = pd.concat([master_df, recording_df], axis=0).reset_index(drop=True)\n",
    "        wilcox_key = f'{event} vs {baseline_window}second baseline'\n",
    "        self.collection.wilcox_dfs[wilcox_key] = master_df\n",
    "        return master_df\n",
    "\n",
    "    def wilcox_baseline_v_event_plots(self, recording, wilcoxon_df, event, equalize, baseline, title, p_value=None, units=None): \n",
    "        \"\"\"\n",
    "        plots event triggered average firing rates for units of a given recording. \n",
    "        optional filtering for p value threshold and unit ids. \n",
    "\n",
    "        Args(8 total, 6 required):\n",
    "            recording: an EphysRecording instance, where the wilcoxon stats and plots will come from\n",
    "            wilcoxon_df: df, the return value from wilcox_baseline_v_event_stats fxn\n",
    "            event: str, event type of which ehpys snippets happen during\n",
    "            equalize: float, length (s) of events used by padding with post event time\n",
    "                or trimming events all to equalize (s) long used in stat\n",
    "            baseline_window: int, default=0, seconds prior to start of event used in stat\n",
    "            title: str, title of figure\n",
    "            p_value: int, default=None, all p values less than will be plotted\n",
    "            units: lst, default=None, list of unit ids (ints) to be plotted\n",
    "\n",
    "        Returns:\n",
    "            none\n",
    "        \"\"\" \n",
    "        units_to_plot = []\n",
    "        if p_value is not None:\n",
    "            for unit in wilcoxon_df.columns.tolist():\n",
    "                if wilcoxon_df[unit][1] < p_value:\n",
    "                      units_to_plot.append(unit)\n",
    "        else:\n",
    "            if units is None:\n",
    "                units_to_plot = wilcoxon_df.columns.tolist()\n",
    "            else:\n",
    "                units_to_plot = units\n",
    "        no_plots = len(units_to_plot)\n",
    "        height_fig = math.ceil(no_plots/3)\n",
    "        i = 1\n",
    "        plt.figure(figsize=(20,4*height_fig))\n",
    "        unit_event_firing_rates = self.get_unit_event_firing_rates(\n",
    "            recording,\n",
    "            event,\n",
    "            equalize,\n",
    "            baseline,\n",
    "            0\n",
    "            )\n",
    "        for unit in units_to_plot:\n",
    "            mean_arr = np.mean(unit_event_firing_rates[unit], axis=0)\n",
    "            sem_arr = sem(unit_event_firing_rates[unit], axis=0)\n",
    "            p_value = wilcoxon_df[unit][1]\n",
    "            x = np.linspace(start=-baseline_window,stop=equalize,num=len(mean_arr))\n",
    "            plt.subplot(height_fig,3,i)\n",
    "            plt.plot(x, mean_arr, c= 'b')\n",
    "            plt.axvline(x=0, color='r', linestyle='--')\n",
    "            plt.fill_between(x, mean_arr-sem_arr, mean_arr+sem_arr, alpha=0.2)\n",
    "            plt.title(f'Unit {unit} Average (p={p_value})')\n",
    "            i+=1\n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "\n",
    "    def wilcoxon_event_v_event_stats(self, recording, event1, event2, equalize): \n",
    "        \"\"\"\n",
    "        calculates wilcoxon signed-rank test for average firing rates between\n",
    "        two events for a given recording. the resulting dataframe of wilcoxon stats\n",
    "        and p values for every unit is added to a dictionary of dataframes for that\n",
    "        recording. \n",
    "\n",
    "        Key for this dictionary item is '{event1} vs {event2}' \n",
    "        and the value is the dataframe. \n",
    "        \n",
    "        Args (4 total):\n",
    "            recording: EphysRecording instance\n",
    "            event1: str, first event type firing rates for stats to be run on\n",
    "            event2: str, second event type firing rates for stats to be run on\n",
    "            equalize: float, length (s) of events used by padding with post event time\n",
    "                or trimming events all to equalize (s) long used in stat\n",
    "    \n",
    "        Return (1):\n",
    "            wilcoxon_df: pandas dataframe, columns are unit ids, \n",
    "            row[0] are wilcoxon statistics and row[1] are p values \n",
    "        \n",
    "        \"\"\"\n",
    "        unit_event1_firing_rates = self.get_unit_event_firing_rates(recording, event1, equalize, 0, 0)\n",
    "        unit_event2_firing_rates = self.get_unit_event_firing_rates(recording, event2, equalize, 0, 0)\n",
    "        unit_averages = {}\n",
    "        for unit in unit_event1_firing_rates.keys():\n",
    "            try:\n",
    "                event1_averages = [mean(event) for event in unit_event1_firing_rates[unit]]\n",
    "                event2_averages = [mean(event) for event in unit_event2_firing_rates[unit]]\n",
    "                unit_averages[unit] = [event1_averages, event2_averages]\n",
    "            except StatisticsError as e:\n",
    "                print(f'Unit {unit} has {len(recording.unit_timestamps[unit])} spikes')\n",
    "        wilcoxon_stats = {}\n",
    "        for unit in unit_averages.keys(): \n",
    "            wilcoxon_stats[unit] = wilcoxon(unit_averages[unit][0], unit_averages[unit][1], method = 'approx')\n",
    "        wilcoxon_df = pd.DataFrame.from_dict(wilcoxon_stats)\n",
    "        wilcox_key = f'{event1 } vs {event2}'\n",
    "        recording.wilcox_dfs[wilcox_key] = wilcoxon_df\n",
    "        return wilcoxon_df\n",
    "\n",
    "    def wilcox_event_v_event_collection(self, event1, event2, equalize):  \n",
    "        \"\"\" \n",
    "        Runs a wilcoxon signed rank test on all good units of \n",
    "        all recordings in the collection on the \n",
    "        given event's firing rate versus another given event's firing rate.\n",
    "    \n",
    "        Creates a dataframe with rows for each unit and columns representing \n",
    "        Wilcoxon stats, p values, orginal unit ids, recording,\n",
    "        subject and the events given.  Dataframe is saved in the collections\n",
    "        wilcox_dfs dictionary, key is '{event1} vs {event2}' \n",
    "\n",
    "        Args(3 total):\n",
    "            event1: str, first event type firing rates for stats to be run on\n",
    "            event2: str, second event type firing rates for stats to be run on \n",
    "            equalize: float, length (s) of events used by padding with post event time\n",
    "                or trimming events all to equalize (s) long used in stat\n",
    "        \n",
    "        Returns (1):\n",
    "            master_df: df, rows for each unit and columns representing \n",
    "            Wilcoxon stats, p values, orginal unit ids, recording,\n",
    "            subject and the events given\n",
    "        \"\"\"\n",
    "        is_first = True\n",
    "        for recording_name, recording in self.collection.item():\n",
    "            recording_df = self.wilcox_event_v_event_stats(self, recording, event1, event2, equalize)\n",
    "            recording_df = recording_df.transpose().reset_index()\n",
    "            recording_df = recording_df.rename(column={'index':'original unit id'})\n",
    "            recording_df['Recording'] = recording_name\n",
    "            recording_df['Subject'] = recording.subject\n",
    "            recording_df['Event'] = [event1, event2]\n",
    "            master_df = pd.concat([master_df, recording_df], axis=0).reset_index(drop=True)\n",
    "            if is_first:\n",
    "                master_df = recording_df\n",
    "                is_first = False\n",
    "            else:\n",
    "                master_df = pd.concat([master_df, recording_df], axis=0).reset_index(drop=True)\n",
    "        wilcox_key = f'{event1} vs {event2}'\n",
    "        self.wilcox_dfs[wilcox_key] = master_df\n",
    "        return master_df\n",
    "\n",
    "    def wilcox_event_v_event_plots(self, recording, wilcoxon_df, event1, event2, equalize, pre_window, title, p_value=None, units=None):\n",
    "        \"\"\"\n",
    "        plots event triggered average firing rates for units\n",
    "        all events need to be the same length\n",
    "\n",
    "         Args(8 total, 6 required):\n",
    "            recording: an EphysRecording instance, where the wilcoxon stats and plots will come from\n",
    "            wilcoxon_df: df, the return value from wilcox_baseline_v_event_stats fxn\n",
    "            event1: str, first event type firing rates for stats to be run on\n",
    "            event2: str, second event type firing rates for stats to be run on\n",
    "            equalize: float, length (s) of events used by padding with post event time\n",
    "                or trimming events all to equalize (s) long used in stat\n",
    "            pre_window: int, length(s) of time prior to event to be plotted\n",
    "            title: str, title of figure\n",
    "            p_value: int, default=None, all p values less than will be plotted\n",
    "            units: lst, default=None, list of unit ids (ints) to be plotted\n",
    "\n",
    "\n",
    "        Returns:\n",
    "            none\n",
    "        \"\"\" \n",
    "        units_to_plot = []\n",
    "        if p_value is not None:\n",
    "            for unit in wilcoxon_df.columns.tolist():\n",
    "                if wilcoxon_df[unit][1] < p_value:\n",
    "                      units_to_plot.append(unit)\n",
    "        else:\n",
    "            if units is None:\n",
    "                units_to_plot = wilcoxon_df.columns.tolist()\n",
    "            else:\n",
    "                units_to_plot = units\n",
    "        no_plots = len(units_to_plot)\n",
    "        height_fig = math.ceil(no_plots/3)\n",
    "        i = 1\n",
    "        plt.figure(figsize=(20,4*height_fig))\n",
    "        unit_event1_firing_rates = self.get_unit_event_firing_rates(recording, event1, equalize, pre_window, 0)\n",
    "        unit_event2_firing_rates = self.get_unit_event_firing_rates(recording, event2, equalize, pre_window, 0)\n",
    "        for unit in units_to_plot:\n",
    "            mean1_arr = np.mean(unit_event1_firing_rates[unit], axis=0)\n",
    "            sem1_arr = sem(unit_event1_firing_rates[unit], axis=0)\n",
    "            mean2_arr = np.mean(unit_event2_firing_rates[unit], axis=0)\n",
    "            sem2_arr = sem(unit_event2_firing_rates[unit], axis=0)\n",
    "            p_value = wilcoxon_df[unit][1]\n",
    "            x = np.linspace(start=-pre_window,stop=equalize,num=len(mean1_arr))\n",
    "            plt.subplot(height_fig,3,i)\n",
    "            plt.plot(x, mean1_arr, c= 'b', label = event1)\n",
    "            plt.fill_between(x, mean1_arr-sem1_arr, mean1_arr+sem1_arr, alpha=0.2)\n",
    "            plt.plot(x, mean2_arr, c= 'k', label = event2)\n",
    "            plt.fill_between(x, mean2_arr-sem2_arr, mean2_arr+sem2_arr, alpha=0.2, color = 'k')\n",
    "            plt.axvline(x=0, color='r', linestyle='--')\n",
    "            plt.title(f'Unit {unit} Average (p={p_value})')\n",
    "            plt.legend()\n",
    "            i+=1\n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "\n",
    "    def get_zscore(self, recording, event, baseline_window, equalize):\n",
    "        \"\"\"\n",
    "        Calculates zscored event average firing rates per unit including a baseline window (s).\n",
    "        Takes in a recording and an event and returns a dictionary of unit ids to z scored\n",
    "        averaged firing rates. \n",
    "        It also assigns this dictionary as the value to a zscored event dictionary of the recording. \n",
    "        Such that recording.zscored_events[event] = {unit id: np.array(zscored average event firing rates)}\n",
    "\n",
    "        Args(4 total, 4 required):\n",
    "            recording: EphysRecording instance, recording that is being zscored\n",
    "            event: str, event type whose average firing rates are being z-scored\n",
    "            baseline_window: int, length (s) of time prior to event onset to be included in \n",
    "                             calculations\n",
    "            equalize: {user_defined, 'max', 'average'}, equalizes lengths of events\n",
    "                by padding with post event time or trimming event\n",
    "                user_defined: float, makes all events user_defined (s) long   \n",
    "                'max': makes all events as long as the longest event \n",
    "                'average': makes all events as long as the average event length\n",
    "\n",
    "        Returns(1):\n",
    "            zscored_events: dict, of units to z scored average event firing rates\n",
    "                            keys: str, unit ids\n",
    "                            values: np.array, average z scared firing rates\n",
    "        \"\"\"\n",
    "        preevent_baselines = np.array([pre_event_window(event, baseline_window) for event in recording.event_dict[event]])\n",
    "        unit_event_firing_rates = self.get_unit_event_firing_rates(recording, equalize, baseline_window, 0)\n",
    "        unit_preevent_firing_rates = self.get_unit_event_firing_rates(recording, preevent_baselines, baseline_window, 0, 0)\n",
    "        zscored_events = {}\n",
    "        for unit in unit_event_firing_rates:\n",
    "            #calculate average event across all events per unit\n",
    "            event_average = np.mean(unit_event_firing_rates[unit], axis = 0)\n",
    "            #one average for all preevents \n",
    "            preevent_average = np.mean(unit_preevent_firing_rates[unit], axis = 0)\n",
    "            mew = np.mean(preevent_average)\n",
    "            sigma = np.std(preevent_average)\n",
    "            if mew + sigma != 0:\n",
    "                zscored_event = [(event_bin - mew)/sigma for event_bin in event_average]\n",
    "                zscored_events[unit] = zscored_event\n",
    "        recording.zscored_events[event] = zscored_events\n",
    "        return zscored_events\n",
    "        \n",
    "    def get_zscore_collection(self, event, baseline_window, equalize):\n",
    "        \"\"\"\n",
    "        calculates z-scored event average firing rates for all recordings in the collection. \n",
    "        assigns a dataframe of all zscored event firing rates with columns for original unit id,\n",
    "        recording name, and subject as a value in zscored_event dictionary attribute of the colleciton\n",
    "        such that: collection.zscored_events[event vs baseline window] = dataframe\n",
    "\n",
    "        Args (3 total, 3 required):\n",
    "            event: str, event type whose average firing rates are being z-scored\n",
    "            baseline_window: int, length (s) of time prior to event onset to be included in \n",
    "                             calculations\n",
    "            equalize: {user_defined, 'max', 'average'}, equalizes lengths of events\n",
    "                by padding with post event time or trimming event\n",
    "                user_defined: float, makes all events user_defined (s) long   \n",
    "                'max': makes all events as long as the longest event \n",
    "                'average': makes all events as long as the average event length\n",
    "        \n",
    "        Returns:\n",
    "            none\n",
    "        \"\"\"\n",
    "        is_first = True \n",
    "        for recording_name, recording in self.collection.values():\n",
    "            zscored_events = self.get_zscore(recording, event, baseline_window, equalize)\n",
    "            zscored_events_df = pd.DataFrame.from_dict(zscored_events, orient='index')\n",
    "            zscored_events_df = zscored_events_df.reset_index().rename(column={'index': 'original unit id'})\n",
    "            zscored_events_df['Recording'] = recording_name\n",
    "            zscored_events_df['Subject'] = recording.subject\n",
    "            zscored_events_df['Event'] = [event, baseline_window]\n",
    "            if is_first:\n",
    "                master_df = zscored_events_df\n",
    "                is_first = False    \n",
    "            else:\n",
    "                master_df = pd.concat([master_df, zscored_events_df], axis=0).reset_index(drop=True)\n",
    "        zscore_key = f'{event} vs {baseline_window}second baseline'\n",
    "        self.collection.zscored_events[zscore_key] = master_df\n",
    "        \n",
    "    def get_zcore_plot(self, recording, event, equalize, baseline_window, title):\n",
    "        \"\"\"\n",
    "        plots z-scored average event firing rate for the population of good units with SEM \n",
    "        and the z-scored average event firing rate for each good unit individually.\n",
    "        Event plotted is the event that was used to create the argument zscored_events\n",
    "\n",
    "        Args (5 total, 5 required):\n",
    "            recording: EphysRecording instance, recording to be plotted\n",
    "            event: str, event type whose average z-scored firing rates will be plotted\n",
    "            baseline_window: int, length (s) of time prior to event onset plotted\n",
    "            equalize: int, length (s) of event plotted\n",
    "            title: str, title of plot\n",
    "        \n",
    "        Return:\n",
    "            none    \n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(20,6))\n",
    "        zscored_unit_event_firing_rates = recording.zscored_events[event]\n",
    "        zscore_pop = np.array(list(zscored_unit_event_firing_rates.values()))\n",
    "        mean_arr = np.mean(zscore_pop, axis=0)\n",
    "        sem_arr = sem(zscore_pop, axis=0)\n",
    "        x = np.linspace(start=-baseline_window,stop=zequalize,num=len(mean_arr))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(x, mean_arr, c= 'b')\n",
    "        plt.axvline(x=0, color='r', linestyle='--')\n",
    "        plt.fill_between(x, mean_arr-sem_arr, mean_arr+sem_arr, alpha=0.2)\n",
    "        plt.title(f'Population z-score')\n",
    "        plt.subplot(1,2,2)\n",
    "        for unit in zscored_unit_event_firing_rates.keys():\n",
    "            plt.plot(x, zscored_unit_event_firing_rates[unit], linewidth = .5)\n",
    "            plt.axvline(x=0, color='r', linestyle='--')\n",
    "            plt.title('Unit z-score')\n",
    "        plt.suptitle(f'{title} Z-scored average')\n",
    "        plt.show()        \n",
    "\n",
    "    def PCA_trajectories(self, events, equalize, n_components=2, pre_window = 0, post_window = 0):\n",
    "        \"\"\"\n",
    "        calculates a PCA matrix (n_components = 3) where each data point represent a timebin \n",
    "        PCA space is calculated from a matrix of all units and all timebins \n",
    "        from every type of event in event dict.\n",
    "        PCA_key is a numpy array of strings, whose index correlates with event\n",
    "        type for that data point of the same index for all PCs in the PCA_matrix\n",
    "        PCA_matrix is assigned to self.PCA_matrix and the key is assigned\n",
    "        as self.PCA_key. \n",
    "\n",
    "        Args (3 total, 2 required):\n",
    "            equalize: int, length (s) of event transformed by PCA \n",
    "            pre_window: int, length (s) of time prior to event onset included in PCA\n",
    "            post_window: int, default=0, length(s) of time after equalize (s) included in PCA\n",
    "        \n",
    "        Returns:\n",
    "            none\n",
    "\n",
    "        \"\"\"\n",
    "        PCA_matrix_dict = {}\n",
    "        PCA_key_dict = {}\n",
    "        for recording_name, recording in self.collection.items():\n",
    "            is_first = True\n",
    "            for unit in recording.unit_firing_rates.keys():\n",
    "                for event in self.event_dict.keys(): \n",
    "                    unit_event_firing_rates = self.get_unit_event_firing_rates(event, equalize, pre_window, post_window)\n",
    "                    unit_event_average = get_unit_average_events(unit_event_firing_rates) \n",
    "                    if first_event:\n",
    "                        PCA_matrix_dict[unit] = unit_event_average[unit]\n",
    "                        PCA_key_dict[unit] = [event] * int((equalize + pre_window + post_window) * 1000 / self.timebin)\n",
    "                        is_first = False\n",
    "                    else:\n",
    "                        PCA_matrix_dict[unit] = np.concatenate((PCA_matrix_dict[unit], unit_event_average[unit]), axis = 0)\n",
    "                        next_event_key = [event] * int((equalize + pre_window + post_window) * 1000 / self.timebin)\n",
    "                        PCA_key_dict[unit] = np.concatenate((PCA_key_dict[unit], next_event_key), axis = 0)\n",
    "        PCA_matrix = np.array([v for v in PCA_matrix_dict.values()])\n",
    "        PCA_matrix = np.transpose(PCA_matrix)\n",
    "        PCA_key = np.array([v for v in PCA_key_dict.values()])\n",
    "        PCA_key = PCA_key[0]\n",
    "        pca = PCA(n_components=3)\n",
    "        transformed_matrix = pca.fit_transform(PCA_matrix)\n",
    "        self.PCA_matrix = transformed_matrix\n",
    "        self.PCA_key = PCA_key\n",
    "        self.PCA_equalize = equalize\n",
    "        self.PCA_pre_window = pre_window\n",
    "        self.PCA_post_window = post_window\n",
    "        \n",
    "      def PCA_EDA_plot(self):\n",
    "        \"\"\"\n",
    "        Plots PCA trajectories calculated in PCA_trajectories using the same\n",
    "        pre window, post window, and equalize parameters. Each event type is\n",
    "        a different color. Preevent start is signified by a square, onset of behavior \n",
    "        signified by a triangle, and the end of the event is signified by a circle. \n",
    "        If post-event time is included that end of post event time is signified by a diamond. \n",
    "\n",
    "        Args:\n",
    "            none\n",
    "        \n",
    "        Returns:\n",
    "            none\n",
    "        \"\"\"\n",
    "        post_window = self.PCA_post_window\n",
    "        pre_window = self.PCA_pre_window\n",
    "        equalize = self.PCA_equalize\n",
    "        event_lengths = int((equalize + pre_window + post_window) * 1000 / self.timebin)\n",
    "        event_end = int((equalize +pre_window) * 1000 / self.timebin)\n",
    "        pre_window = pre_window * 1000 / self.timebin\n",
    "        post_window = post_window * 1000 / self.timebin\n",
    "        colors_dict = plt.cm.colors.CSS4_COLORS\n",
    "        colors = list(colors_dict.values())\n",
    "        col_counter = 10\n",
    "        for i in range(0,len(self.PCA_key),event_lengths):\n",
    "            event_label = self.PCA_key[i]\n",
    "            onset = int(i+pre_window -1)\n",
    "            end = int(i + event_end -1)\n",
    "            post = int(i+event_lengths - 1 )\n",
    "            plt.scatter(self.PCA_matrix[i:i+event_lengths, 0], \n",
    "                        self.PCA_matrix[i:i+event_lengths, 1],\n",
    "                        label = event_label,\n",
    "                        s = 5, c=colors[col_counter])\n",
    "            plt.scatter(self.PCA_matrix[i,0], self.PCA_matrix[i,1],\n",
    "                        marker = 's', s = 100, c = 'w', edgecolors=colors[col_counter])\n",
    "            plt.scatter(self.PCA_matrix[onset, 0], self.PCA_matrix[onset, 1],\n",
    "                        marker = '^', s = 150, c = 'w', edgecolors=colors[col_counter])\n",
    "            plt.scatter(self.PCA_matrix[end,0], self.PCA_matrix[end,1],\n",
    "                        marker = 'o', s = 100, c = 'w', edgecolors=colors[col_counter])\n",
    "            if post_window != 0:\n",
    "                plt.scatter(self.PCA_matrix[post,0], self.PCA_matrix[post,1],\n",
    "                        marker = 'D', s = 100, c = 'w', edgecolors=colors[col_counter])\n",
    "            col_counter +=1\n",
    "        plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "        if post_window !=0:    \n",
    "            plt.title('Preevent = square, Onset = triangle, End of event = circle, Post event = Diamond')\n",
    "        else:\n",
    "            plt.title('Preevent = square, Onset = triangle, End of event = circle')\n",
    "        plt.show()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ephys_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
